{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi . \t嗨 。 \tCC-BY 2 . 0 (France) Attribution: tatoeba . org #538123 (CM) & #891077 (Martha)\n",
      "\n",
      "['Oh', 'no', '!'] ['不', '会', '吧', '。']\n",
      "3 : 29\n",
      "4 : 568\n",
      "5 : 1741\n",
      "6 : 3871\n",
      "7 : 4945\n",
      "8 : 5708\n",
      "9 : 5250\n",
      "10 : 2175\n",
      "11 : 1376\n",
      "12 : 847\n",
      "13 : 596\n",
      "14 : 329\n",
      "15 : 216\n",
      "16 : 140\n",
      "17 : 69\n",
      "18 : 53\n",
      "19 : 30\n",
      "20 : 15\n",
      "21 : 11\n",
      "22 : 5\n",
      "23 : 5\n",
      "24 : 3\n",
      "26 : 1\n",
      "30 : 1\n",
      "31 : 1\n",
      "35 : 1\n",
      "4 : 9\n",
      "5 : 117\n",
      "6 : 426\n",
      "7 : 1172\n",
      "8 : 2258\n",
      "9 : 3271\n",
      "10 : 3828\n",
      "11 : 3791\n",
      "12 : 3516\n",
      "13 : 2716\n",
      "14 : 2002\n",
      "15 : 1540\n",
      "16 : 966\n",
      "17 : 671\n",
      "18 : 502\n",
      "19 : 328\n",
      "20 : 264\n",
      "21 : 180\n",
      "22 : 127\n",
      "23 : 80\n",
      "24 : 60\n",
      "25 : 38\n",
      "26 : 21\n",
      "27 : 29\n",
      "28 : 20\n",
      "29 : 12\n",
      "30 : 9\n",
      "31 : 6\n",
      "32 : 5\n",
      "33 : 5\n",
      "34 : 7\n",
      "36 : 2\n",
      "38 : 2\n",
      "39 : 1\n",
      "40 : 2\n",
      "42 : 1\n",
      "46 : 2\n",
      "3 2\n",
      "3 2\n",
      "3629 2643\n"
     ]
    }
   ],
   "source": [
    "with open(\"cmn.txt\", encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "sep = \".!?,。？！，\"\n",
    "lines = [\"\".join([char if char not in sep else \" \" + char + \" \" for char in line]) for line in lines]\n",
    "print(lines[0])\n",
    "lines = [line.split(\"\\t\")[:2] for line in lines]\n",
    "lines = [(line_pair[0].split(), line_pair[1].split()) for line_pair in lines]\n",
    "\n",
    "source_sequence = []\n",
    "target_sequence = []\n",
    "for line in lines:\n",
    "    source_sequence.append(line[0])\n",
    "    target = []\n",
    "    for seq in line[1]:\n",
    "        if len(seq) == 1:\n",
    "            target.append(seq)\n",
    "        else:\n",
    "            target.extend([char for char in seq])\n",
    "    target_sequence.append(target)\n",
    "print(source_sequence[10], target_sequence[10])\n",
    "\n",
    "source_sequence = [sequence + [\"<eos>\"] for sequence in source_sequence]\n",
    "target_sequence = [[\"<bos>\"] + sequence + [\"<eos>\"] for sequence in target_sequence]\n",
    "\n",
    "def sequence_length(sequences):\n",
    "    length_dict = {}\n",
    "    for sequence in sequences:\n",
    "        if length_dict.get(len(sequence), -1) == -1:\n",
    "            length_dict[len(sequence)] = 1\n",
    "        else:\n",
    "            length_dict[len(sequence)] += 1\n",
    "    keys = [k for k in length_dict]\n",
    "    keys.sort()\n",
    "    for k in keys:\n",
    "        print(k, \":\", length_dict[k])\n",
    "\n",
    "sequence_length(source_sequence)\n",
    "sequence_length(target_sequence)\n",
    "\n",
    "def padding_sequence(padding_size, sequence):\n",
    "    if len(sequence) > padding_size:\n",
    "        return sequence[:padding_size]\n",
    "    elif len(sequence) < padding_size:\n",
    "        for i in range(len(sequence), padding_size):\n",
    "            sequence.append(\"<pad>\")\n",
    "    return sequence\n",
    "    \n",
    "source_sequence = [padding_sequence(20, sequence) for sequence in source_sequence]\n",
    "target_sequence = [padding_sequence(30, sequence) for sequence in target_sequence]\n",
    "\n",
    "source_count_dict = {}\n",
    "target_count_dict = {}\n",
    "\n",
    "for sequence in source_sequence:\n",
    "    for word in sequence:\n",
    "        if source_count_dict.get(word, -1) == -1:\n",
    "            source_count_dict[word] = 0\n",
    "        else:\n",
    "            source_count_dict[word] += 1\n",
    "for sequence in target_sequence:\n",
    "    for word in sequence:\n",
    "        if target_count_dict.get(word, -1) == -1:\n",
    "            target_count_dict[word] = 0\n",
    "        else:\n",
    "            target_count_dict[word] += 1\n",
    "\n",
    "target_words = [\"<unknown>\", \"<pad>\", \"<eos>\", \"<bos>\"]\n",
    "source_words = [\"<unknown>\", \"<pad>\", \"<eos>\", \"<bos>\"]\n",
    "target_dict = {\"<unknown>\":0, \"<pad>\":1, \"<eos>\":2, \"<bos>\":3}\n",
    "source_dict = {\"<unknown>\":0, \"<pad>\":1, \"<eos>\":2, \"<bos>\":3}\n",
    "\n",
    "print(target_dict[\"<bos>\"], target_dict[\"<eos>\"])\n",
    "for k in source_count_dict:\n",
    "    if source_count_dict[k] < 2 or source_dict.get(k, -1) != -1:\n",
    "        continue\n",
    "    source_dict[k] = len(source_words)\n",
    "    source_words.append(k)\n",
    "for k in target_count_dict:\n",
    "    if target_count_dict[k] < 2 or target_dict.get(k, -1) != -1:\n",
    "        continue\n",
    "    target_dict[k] = len(target_words)\n",
    "    target_words.append(k)\n",
    "\n",
    "print(target_dict[\"<bos>\"], target_dict[\"<eos>\"])\n",
    "print(len(source_dict), len(target_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([4, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "       device='cuda:0'), tensor([3, 4, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "[tensor([[  11,  238,  217,  918,  164,  400,   79,    5,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [3448,  696, 3568,    0,  466, 1565, 3107,  466, 3438,    5,    2,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0'), tensor([[   3,   19,   23,  386,  555,   36,  207,   78,  672,  466,    5,    2,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [   3,  989,  312, 2227, 1189,   10, 1938, 1470,   68, 1121,   22, 2596,\n",
      "         1772,  786,   10,  998, 1569,    5,    2,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1]], device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, source_lines, target_lines, source_words, target_words, source_dict, target_dict) -> None:\n",
    "        super().__init__()\n",
    "        self.source_lines = source_lines\n",
    "        self.target_lines = target_lines\n",
    "        self.source_words = source_words\n",
    "        self.target_words = target_words\n",
    "        self.source_dict = source_dict\n",
    "        self.target_dict = target_dict\n",
    "    def __getitem__(self, index):\n",
    "        line = self.source_lines[index]\n",
    "        source_index = [self.source_dict.get(word, 0) for word in line]\n",
    "        line = self.target_lines[index]\n",
    "        target_index = [self.target_dict.get(word, 0)  for word in line]\n",
    "        # here we use tensor, so we can get [batch_size, sequence_length] tensor. or we will get wierd things.\n",
    "        return torch.tensor(source_index).cuda(), torch.tensor(target_index).cuda()\n",
    "    def __len__(self):\n",
    "        return len(self.source_lines)\n",
    "seq_data_set = SeqDataset(source_lines=source_sequence,\n",
    "                          target_lines=target_sequence,\n",
    "                          source_words=source_words,\n",
    "                          target_words=target_words,\n",
    "                          source_dict=source_dict,\n",
    "                          target_dict=target_dict)\n",
    "print(seq_data_set[0])\n",
    "train_data_loader = DataLoader(dataset=seq_data_set, batch_size=2, shuffle=True)\n",
    "for iter in train_data_loader:\n",
    "    # print(iter[0].shape, iter[1].shape)\n",
    "    print(iter)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def init_state(self, state):\n",
    "        raise NotImplementedError\n",
    "    def forward(self, x, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder_ = encoder\n",
    "        self.decoder_ = decoder\n",
    "    def forward(self, x, y):\n",
    "        encoder_output = self.encoder_(x)\n",
    "        state = self.decoder_.init_state(encoder_output)\n",
    "        decoder_output = self.decoder_(y, state)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEncoder(Encoder):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = embedding_dim\n",
    "        self.num_layers = 2\n",
    "        self.word2vec = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, bias=True, dropout=0.5)\n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros((self.num_layers, x.shape[1], self.hidden_dim)).cuda()\n",
    "        embedding = self.word2vec(x)\n",
    "        output, hidden = self.gru(embedding, hidden_state)\n",
    "        return hidden\n",
    "\n",
    "class GRUDecoder(Decoder):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = embedding_dim \n",
    "        self.num_layers = 2\n",
    "        self.word2vec = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(input_size=embedding_dim + self.hidden_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, bias=True, dropout=0.5)\n",
    "        self.linear = nn.Linear(self.hidden_dim, vocab_size)    \n",
    "    def init_state(self, state):\n",
    "        return state\n",
    "    def forward(self, y, state):\n",
    "        embedding = self.word2vec(y)\n",
    "        input = torch.cat((embedding, state[-1].repeat([y.shape[0], 1, 1])), 2)\n",
    "        output, hidden = self.gru(input, state)\n",
    "        one_hot = self.linear(output)\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 683, 684, 212, 503,   5,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5], device='cuda:0') tensor([[ 0.7792,  1.1420,  1.2677,  ...,  1.5943,  1.5274,  1.5312],\n",
      "        [-2.1227, -2.7920, -3.0048,  ..., -3.2786, -3.2270, -3.1910],\n",
      "        [ 2.7881,  3.7700,  4.0474,  ...,  4.4602,  4.3835,  4.3593],\n",
      "        ...,\n",
      "        [-1.8133, -2.3629, -2.5257,  ..., -2.5716, -2.7218, -2.7439],\n",
      "        [-1.7221, -1.9065, -1.9314,  ..., -1.4448, -1.5925, -1.5959],\n",
      "        [-2.0462, -2.2365, -2.3822,  ..., -2.1730, -2.3098, -2.3208]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '准', '备', '晚', '餐', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8832, -0.7876,  1.1280, -0.8036, -0.2134, -0.2482, -0.0939, -0.6604,\n",
      "         0.9547,  0.7142, -0.2640, -1.6525, -1.6465, -0.1376, -0.8976,  0.4122,\n",
      "        -1.2540, -0.1875, -0.9614,  1.2262,  1.2884, -0.9444,  2.2242,  0.9261,\n",
      "         0.7613,  0.2690,  1.4903,  0.4445,  0.7056, -0.3284, -0.0167, -2.4215],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7170, -0.3624, -0.3935, -0.3214,  1.9895,  0.4418,  0.5117, -1.1290,\n",
      "         0.3371, -1.7529,  1.9570, -0.5343, -0.6823,  0.7506,  0.0583,  0.8711,\n",
      "        -1.7376,  0.3863, -0.5704,  0.7403,  0.1813,  1.3706, -0.5557, -0.2465,\n",
      "         0.4563, -1.5757, -2.9423, -0.9556,  0.1220, -1.4848, -0.0079, -0.3151],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1836.2074, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19,  51, 163, 271, 164, 161, 502, 746, 252,  33,   2,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 19, 19,  5,  5,  5,  5,  5,  5,  5,  2,  2,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  2,  5,  2,  5], device='cuda:0') tensor([[ 1.4490,  1.6689,  1.7866,  ...,  2.1374,  2.2405,  2.1925],\n",
      "        [-3.0747, -3.3078, -3.4836,  ..., -3.8513, -4.0908, -4.0408],\n",
      "        [ 3.1967,  3.5605,  3.8355,  ...,  4.9629,  5.3926,  5.1960],\n",
      "        ...,\n",
      "        [-2.3762, -2.6233, -2.7880,  ..., -3.0024, -3.2002, -3.1743],\n",
      "        [-2.4997, -2.6062, -2.5957,  ..., -2.2180, -2.2022, -2.2114],\n",
      "        [-2.8391, -2.9337, -3.0267,  ..., -3.3759, -3.2898, -3.3995]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '能', '在', '這', '裡', '吃', '午', '飯', '嗎', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '我', '我', '。', '。', '。', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '<eos>', '。', '<eos>', '。']\n",
      "x embedding 0 tensor([-0.8808, -0.7899,  1.1311, -0.8049, -0.2091, -0.2464, -0.0962, -0.6615,\n",
      "         0.9550,  0.7150, -0.2653, -1.6647, -1.6452, -0.1361, -0.8971,  0.4125,\n",
      "        -1.2553, -0.1900, -0.9626,  1.2265,  1.2893, -0.9426,  2.2241,  0.9284,\n",
      "         0.7615,  0.2681,  1.4875,  0.4458,  0.7064, -0.3258, -0.0163, -2.4212],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7492, -0.3698, -0.3729, -0.3516,  1.9780,  0.4305,  0.4783, -1.1135,\n",
      "         0.3443, -1.7257,  1.9868, -0.5420, -0.7127,  0.7240,  0.0836,  0.9132,\n",
      "        -1.7657,  0.4138, -0.5920,  0.7108,  0.2115,  1.4065, -0.5838, -0.2717,\n",
      "         0.4211, -1.5986, -2.9163, -0.9868,  0.1455, -1.4923,  0.0168, -0.3341],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1725.9877, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  36,  10, 410, 444,  99,  65,   5,   2,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 19, 19,  5,  5,  5,  5,  2,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.3103,  1.6900,  1.7932,  ...,  2.3645,  2.3330,  2.3295],\n",
      "        [-3.4813, -3.6162, -3.5468,  ..., -4.1889, -4.1504, -4.2744],\n",
      "        [ 2.8959,  3.0341,  2.9036,  ...,  4.9190,  5.1968,  4.6382],\n",
      "        ...,\n",
      "        [-2.6752, -2.8704, -2.7746,  ..., -3.2057, -3.2481, -3.2016],\n",
      "        [-2.6506, -2.8915, -2.8070,  ..., -2.5817, -2.5463, -2.5960],\n",
      "        [-2.9128, -2.9865, -3.0128,  ..., -3.2493, -3.1504, -3.3996]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '的', '新', '車', '很', '棒', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '我', '我', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8807, -0.7937,  1.1320, -0.8037, -0.2098, -0.2475, -0.0943, -0.6604,\n",
      "         0.9566,  0.7142, -0.2635, -1.6669, -1.6465, -0.1372, -0.8954,  0.4133,\n",
      "        -1.2541, -0.1878, -0.9609,  1.2249,  1.2878, -0.9436,  2.2213,  0.9282,\n",
      "         0.7600,  0.2699,  1.4907,  0.4446,  0.7076, -0.3265, -0.0147, -2.4225],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7493, -0.3634, -0.3837, -0.3488,  1.9751,  0.4188,  0.4757, -1.1156,\n",
      "         0.3497, -1.7203,  1.9976, -0.5410, -0.7038,  0.7236,  0.0862,  0.9140,\n",
      "        -1.7676,  0.4077, -0.5971,  0.7082,  0.2115,  1.4101, -0.5908, -0.2580,\n",
      "         0.4175, -1.5904, -2.9094, -0.9882,  0.1418, -1.4944,  0.0200, -0.3242],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1579.2029, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 177,  43,  32,  41, 202,   5,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 19, 19,  5,  5,  5,  2,  5,  5,  5,  5,  5,  2,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.4710,  1.8626,  2.0075,  ...,  2.4682,  2.4576,  2.1687],\n",
      "        [-3.8006, -3.9150, -4.0091,  ..., -4.6243, -4.5974, -4.1564],\n",
      "        [ 3.0305,  2.4887,  2.5118,  ...,  4.3620,  4.2410,  3.5237],\n",
      "        ...,\n",
      "        [-3.1296, -3.0457, -3.0795,  ..., -3.4690, -3.4723, -3.1230],\n",
      "        [-2.4691, -2.8537, -2.8405,  ..., -2.3981, -2.3425, -2.1419],\n",
      "        [-2.7168, -3.0372, -3.1338,  ..., -3.3803, -3.2990, -3.2076]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '她', '沒', '有', '出', '現', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '我', '我', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8771, -0.8092,  1.1423, -0.7977, -0.2160, -0.2494, -0.0843, -0.6541,\n",
      "         0.9619,  0.7085, -0.2565, -1.6812, -1.6528, -0.1421, -0.8874,  0.4138,\n",
      "        -1.2479, -0.1776, -0.9511,  1.2143,  1.2813, -0.9498,  2.2126,  0.9357,\n",
      "         0.7513,  0.2782,  1.5065,  0.4389,  0.7135, -0.3268, -0.0040, -2.4302],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7478, -0.3719, -0.3832, -0.3415,  1.9863,  0.3947,  0.4755, -1.1125,\n",
      "         0.3742, -1.6926,  2.0148, -0.5562, -0.6977,  0.7215,  0.0955,  0.9086,\n",
      "        -1.7556,  0.3981, -0.6043,  0.7032,  0.1937,  1.4123, -0.5949, -0.2477,\n",
      "         0.4183, -1.5748, -2.8993, -0.9885,  0.1278, -1.5005,  0.0218, -0.3094],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1800.8479, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,   24,  544,    6,   78,   69, 1229,  562,  394,    5,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 19, 19, 19,  5,  5,  5,  5,  5,  5,  2,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.2358,  1.5512,  1.6320,  ...,  2.2544,  2.2619,  2.1914],\n",
      "        [-3.9431, -3.7662, -4.0422,  ..., -4.8110, -4.6931, -4.6479],\n",
      "        [ 2.7700,  1.7617,  1.7394,  ...,  3.7050,  3.6985,  3.4922],\n",
      "        ...,\n",
      "        [-3.4833, -3.2146, -3.2213,  ..., -3.5862, -3.6075, -3.5066],\n",
      "        [-2.5481, -2.9760, -2.9857,  ..., -2.5498, -2.4221, -2.4165],\n",
      "        [-2.6804, -2.9604, -3.1433,  ..., -3.5587, -3.5193, -3.4725]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '会', '带', '你', '到', '公', '交', '车', '站', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '我', '我', '我', '。', '。', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.5039e-01, -8.4815e-01,  1.1595e+00, -7.9693e-01, -1.6178e-01,\n",
      "        -2.1985e-01, -8.7404e-02, -6.5726e-01,  9.8469e-01,  7.0539e-01,\n",
      "        -2.5093e-01, -1.7545e+00, -1.6365e+00, -1.2443e-01, -8.8534e-01,\n",
      "         4.2914e-01, -1.2596e+00, -1.6914e-01, -9.4740e-01,  1.2004e+00,\n",
      "         1.3008e+00, -9.4708e-01,  2.1784e+00,  9.7163e-01,  7.3640e-01,\n",
      "         2.8041e-01,  1.4784e+00,  4.4546e-01,  7.2124e-01, -2.9316e-01,\n",
      "         2.2568e-03, -2.4341e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7198, -0.3457, -0.4043, -0.3171,  2.0069,  0.4002,  0.4805, -1.1209,\n",
      "         0.4235, -1.6550,  2.0120, -0.5866, -0.6754,  0.7352,  0.0723,  0.8836,\n",
      "        -1.7242,  0.3657, -0.5851,  0.7194,  0.1788,  1.3890, -0.5600, -0.2183,\n",
      "         0.4481, -1.5579, -2.9021, -0.9667,  0.0894, -1.4793, -0.0136, -0.3142],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1813.9712, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   36,  174,  499,   36, 1253, 1632,   22,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 64, 19, 19, 10,  5,  5,  5,  2,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.3287,  1.6805,  1.6157,  ...,  2.4661,  2.5445,  2.3939],\n",
      "        [-4.1682, -3.7444, -3.7934,  ..., -5.1924, -5.3579, -5.0831],\n",
      "        [ 2.7097,  1.3598,  1.1844,  ...,  3.6448,  3.9326,  3.4159],\n",
      "        ...,\n",
      "        [-3.7813, -3.5861, -3.4857,  ..., -3.9533, -4.0215, -3.8367],\n",
      "        [-2.6678, -3.1908, -3.0128,  ..., -2.6997, -2.8417, -2.6761],\n",
      "        [-2.9225, -2.9838, -2.9952,  ..., -3.7139, -3.8216, -3.7000]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '們', '讓', '他', '簽', '約', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '姆', '我', '我', '的', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7339, -0.9612,  1.2618, -0.7832, -0.0369, -0.1111, -0.0050, -0.6126,\n",
      "         1.0905,  0.6608, -0.1505, -1.8884, -1.6031, -0.0367, -0.8882,  0.5543,\n",
      "        -1.3339, -0.1504, -0.9060,  1.1801,  1.4118, -0.9078,  2.1576,  1.1317,\n",
      "         0.7381,  0.2575,  1.3709,  0.4544,  0.7645, -0.1500,  0.0527, -2.4413],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7076, -0.3018, -0.3877, -0.3082,  2.0280,  0.3817,  0.4819, -1.0929,\n",
      "         0.4776, -1.5815,  2.0442, -0.6514, -0.6584,  0.7345,  0.0823,  0.8695,\n",
      "        -1.7006,  0.3388, -0.5855,  0.7290,  0.1661,  1.3752, -0.5361, -0.1991,\n",
      "         0.4757, -1.5688, -2.9058, -0.9632,  0.0595, -1.4766, -0.0613, -0.3396],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1812.9504, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 353, 220, 444,  99, 150, 147, 335, 154,  22,   5,   2,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 19, 19, 19, 19,  5,  5,  5,  5,  5,  5,  2,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.5585,  1.9374,  1.7939,  ...,  2.4618,  2.4693,  2.6166],\n",
      "        [-4.7101, -4.3664, -4.4596,  ..., -5.4812, -5.4349, -5.7568],\n",
      "        [ 3.1337,  1.7973,  1.2785,  ...,  3.2743,  3.3248,  3.8302],\n",
      "        ...,\n",
      "        [-3.6789, -3.5087, -3.1253,  ..., -3.6818, -3.7043, -3.9107],\n",
      "        [-2.9770, -3.6262, -3.3360,  ..., -2.9168, -2.8595, -3.0637],\n",
      "        [-2.9683, -3.0179, -3.1182,  ..., -3.5045, -3.5175, -3.6137]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '想', '火', '車', '很', '快', '就', '會', '來', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '我', '我', '我', '我', '。', '。', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7204, -1.0160,  1.3091, -0.7983, -0.0098, -0.0607,  0.0332, -0.5821,\n",
      "         1.1844,  0.7123, -0.1325, -1.9251, -1.5653, -0.0273, -0.9129,  0.5890,\n",
      "        -1.3692, -0.1602, -0.9616,  1.2647,  1.4565, -0.8793,  2.1898,  1.1509,\n",
      "         0.8030,  0.2344,  1.3390,  0.4890,  0.7827, -0.0906,  0.0271, -2.4250],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7227, -0.2981, -0.3889, -0.3205,  2.0204,  0.3702,  0.4775, -1.0730,\n",
      "         0.4727, -1.5679,  2.0500, -0.6734, -0.6732,  0.7290,  0.0936,  0.8733,\n",
      "        -1.7096,  0.3459, -0.6015,  0.7173,  0.1795,  1.3858, -0.5407, -0.2009,\n",
      "         0.4728, -1.5738, -2.8893, -0.9733,  0.0661, -1.4917, -0.0615, -0.3415],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1697.7446, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  202, 1079,  306,  605,  498,  354,  239,   15,  648, 2473,   10,\n",
      "         306, 1611,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 64, 23, 60,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  2,  2,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.9976,  1.4817,  1.1391,  ...,  2.2331,  2.5080,  2.4801],\n",
      "        [-3.8437, -3.8822, -3.5875,  ..., -5.3644, -5.9809, -5.9780],\n",
      "        [ 1.9783,  0.8141, -0.1115,  ...,  2.5903,  3.6921,  3.4990],\n",
      "        ...,\n",
      "        [-3.4226, -3.3556, -2.7613,  ..., -3.1939, -3.5249, -3.5395],\n",
      "        [-2.4505, -3.1645, -2.7159,  ..., -2.7913, -3.0750, -3.1130],\n",
      "        [-2.6899, -2.8915, -2.7241,  ..., -3.6911, -3.8209, -3.8105]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '現', '代', '船', '隻', '只', '需', '要', '一', '小', '組', '的', '船', '員', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '姆', '不', '是', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6521, -1.0482,  1.3461, -0.7823,  0.0168, -0.0403,  0.0840, -0.5600,\n",
      "         1.2178,  0.6706, -0.1022, -1.9219, -1.5655, -0.0438, -0.8894,  0.6642,\n",
      "        -1.3649, -0.1373, -0.9636,  1.2665,  1.4625, -0.8618,  2.1755,  1.1720,\n",
      "         0.7920,  0.2582,  1.3473,  0.4682,  0.8083, -0.0757,  0.0705, -2.4486],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7051, -0.2564, -0.4006, -0.2985,  2.0626,  0.3525,  0.4935, -1.0539,\n",
      "         0.5104, -1.5724,  2.0550, -0.6956, -0.6411,  0.7438,  0.1063,  0.8573,\n",
      "        -1.6886,  0.3049, -0.5714,  0.7299,  0.1756,  1.3781, -0.5136, -0.1842,\n",
      "         0.4978, -1.5217, -2.8997, -0.9610,  0.0458, -1.4852, -0.0995, -0.3922],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(2026.2661, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   43,   32,   15,  360,  171, 1532,   78,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6, 64, 60, 60, 10,  5,  5,  5,  2,  2,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.0275,  1.6925,  1.4474,  ...,  2.5738,  2.5351,  2.4971],\n",
      "        [-3.8148, -4.0742, -4.1989,  ..., -6.1039, -6.0111, -5.8304],\n",
      "        [ 1.8693,  0.7024, -0.1614,  ...,  3.2104,  3.0014,  2.9054],\n",
      "        ...,\n",
      "        [-3.4516, -3.4761, -2.9051,  ..., -3.5757, -3.5016, -3.4555],\n",
      "        [-2.3484, -3.2392, -3.0020,  ..., -3.0067, -2.9749, -2.8450],\n",
      "        [-2.7242, -3.0123, -3.0243,  ..., -3.9471, -3.9418, -3.9087]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '沒', '有', '一', '個', '人', '遲', '到', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '姆', '是', '是', '的', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6225, -1.0774,  1.3550, -0.7947,  0.0490, -0.0202,  0.0791, -0.5796,\n",
      "         1.2039,  0.6550, -0.1166, -1.9439, -1.5394, -0.0326, -0.8947,  0.7202,\n",
      "        -1.3848, -0.1531, -0.9785,  1.2756,  1.4758, -0.8166,  2.1814,  1.2126,\n",
      "         0.7972,  0.2493,  1.3315,  0.4765,  0.8020, -0.0607,  0.0805, -2.4418],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7138, -0.2564, -0.3732, -0.3023,  2.0717,  0.3415,  0.4819, -1.0396,\n",
      "         0.5208, -1.5367,  2.0678, -0.7087, -0.6550,  0.7348,  0.1327,  0.8702,\n",
      "        -1.6962,  0.3138, -0.5822,  0.7414,  0.1730,  1.3783, -0.5185, -0.2008,\n",
      "         0.4956, -1.5315, -2.8810, -0.9729,  0.0395, -1.5017, -0.0830, -0.4041],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1518.6409, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   36,   68,  275,  312,  481,  804, 1875,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 64, 60, 10, 10,  5,  5,  5,  2,  2,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.4178,  1.7787,  1.7612,  ...,  2.6087,  2.5474,  2.4833],\n",
      "        [-4.8515, -4.2513, -4.8112,  ..., -6.6534, -6.4647, -6.1985],\n",
      "        [ 2.6343,  0.4666,  0.0663,  ...,  3.7467,  3.1943,  2.9456],\n",
      "        ...,\n",
      "        [-3.9033, -3.5616, -3.3391,  ..., -4.0192, -3.8829, -3.7783],\n",
      "        [-2.9865, -3.4727, -3.4993,  ..., -3.3738, -3.2919, -3.1442],\n",
      "        [-3.2976, -3.2004, -3.2670,  ..., -4.2217, -4.1679, -4.1070]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '点', '头', '以', '示', '鼓', '励', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '姆', '是', '的', '的', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6264, -1.0733,  1.3143, -0.7828,  0.0184, -0.0327,  0.0409, -0.5794,\n",
      "         1.1257,  0.6484, -0.1194, -1.8951, -1.5161, -0.0279, -0.9050,  0.7463,\n",
      "        -1.3805, -0.1576, -0.9795,  1.2857,  1.4598, -0.8175,  2.1698,  1.1572,\n",
      "         0.7825,  0.2555,  1.3233,  0.4791,  0.7859, -0.0778,  0.0151, -2.4204],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7074, -0.2674, -0.3862, -0.2874,  2.0785,  0.3746,  0.4607, -1.0636,\n",
      "         0.5092, -1.5622,  2.0194, -0.6826, -0.6582,  0.7415,  0.1189,  0.8573,\n",
      "        -1.6858,  0.3121, -0.5770,  0.7467,  0.1783,  1.3566, -0.5036, -0.1776,\n",
      "         0.5082, -1.4964, -2.8784, -0.9730,  0.0203, -1.4839, -0.0800, -0.3936],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1691.6907, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3, 1342,   22,  871,  872,  266,   19,  839,   15,  266,  529,  328,\n",
      "         329,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  19,  19,  19,  19,  19,  10,  19, 163,   5,   5,   5,   5,   2,\n",
      "          2,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.5165,  2.3417,  2.3157,  ...,  2.6824,  2.7069,  2.7201],\n",
      "        [-5.3569, -6.1767, -6.6819,  ..., -6.3529, -6.4100, -6.4113],\n",
      "        [ 3.3413,  2.8272,  3.6016,  ...,  3.0488,  3.0625,  2.9718],\n",
      "        ...,\n",
      "        [-3.8785, -4.4071, -4.2742,  ..., -3.9475, -4.0046, -4.0003],\n",
      "        [-3.3028, -4.3873, -4.1850,  ..., -3.2074, -3.2434, -3.3654],\n",
      "        [-3.3466, -3.9512, -4.0917,  ..., -4.2835, -4.3330, -4.2336]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '除', '了', '星', '期', '天', '我', '每', '一', '天', '都', '工', '作', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '我', '我', '我', '我', '我', '的', '我', '在', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6350, -1.0649,  1.2888, -0.7924, -0.0025, -0.0480,  0.0097, -0.5644,\n",
      "         1.0716,  0.6371, -0.1168, -1.8700, -1.5065, -0.0273, -0.9118,  0.7616,\n",
      "        -1.3735, -0.1591, -0.9748,  1.2929,  1.4470, -0.8239,  2.1584,  1.1423,\n",
      "         0.7630,  0.2626,  1.3176,  0.4794,  0.7737, -0.1034, -0.0080, -2.4049],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7143, -0.2824, -0.4009, -0.2897,  2.0612,  0.3846,  0.4541, -1.0807,\n",
      "         0.4857, -1.5724,  2.0022, -0.6653, -0.6765,  0.7245,  0.1105,  0.8588,\n",
      "        -1.6985,  0.3214, -0.5822,  0.7459,  0.1794,  1.3489, -0.5050, -0.1633,\n",
      "         0.5011, -1.5216, -2.8828, -0.9795,  0.0203, -1.4827, -0.0591, -0.3712],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1781.0518, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 202, 163, 559, 529,  23,  15, 356,  22,   5,   2,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 64, 10, 10, 10, 10, 10,  5,  5,  2,  2,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.2937,  2.1691,  2.2064,  ...,  2.5685,  2.6399,  2.6314],\n",
      "        [-4.7600, -6.0788, -5.2233,  ..., -6.3123, -6.6573, -6.9512],\n",
      "        [ 2.2412,  2.1331, -0.2740,  ...,  2.7486,  2.7377,  3.1692],\n",
      "        ...,\n",
      "        [-3.9055, -4.5234, -3.5276,  ..., -4.0253, -4.1081, -4.2099],\n",
      "        [-2.9294, -4.0838, -3.4321,  ..., -3.3541, -3.4473, -3.6708],\n",
      "        [-3.1916, -3.7382, -3.3046,  ..., -3.8407, -4.0000, -3.9354]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '現', '在', '全', '都', '不', '一', '樣', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '姆', '的', '的', '的', '的', '的', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6536, -1.0556,  1.2806, -0.7933, -0.0142, -0.0496,  0.0094, -0.5592,\n",
      "         1.0638,  0.6333, -0.1105, -1.8559, -1.5096, -0.0408, -0.9119,  0.7600,\n",
      "        -1.3719, -0.1568, -0.9697,  1.2896,  1.4424, -0.8313,  2.1465,  1.1229,\n",
      "         0.7478,  0.2735,  1.3181,  0.4682,  0.7739, -0.1221, -0.0243, -2.3980],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7156, -0.2852, -0.4090, -0.2950,  2.0693,  0.3768,  0.4410, -1.0752,\n",
      "         0.4879, -1.5680,  1.9949, -0.6700, -0.6704,  0.7242,  0.1156,  0.8556,\n",
      "        -1.7001,  0.3323, -0.5942,  0.7422,  0.1862,  1.3500, -0.5146, -0.1513,\n",
      "         0.5062, -1.5203, -2.8696, -0.9919,  0.0243, -1.4601, -0.0619, -0.3744],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1886.6381, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  36,  45, 821, 622,  54, 239, 419, 555,  15, 900, 998, 750,   5,\n",
      "          2,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6, 60, 60, 60,  6, 64, 10,  5,  5,  5,  5,  5,  5,  2,  2,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.1741,  1.7388,  2.0764,  ...,  2.7073,  2.7158,  2.6170],\n",
      "        [-4.5567, -4.6612, -4.7679,  ..., -7.1066, -6.9011, -5.8580],\n",
      "        [ 1.6636, -0.1202, -1.1949,  ...,  3.6949,  2.9772,  2.1226],\n",
      "        ...,\n",
      "        [-3.4193, -3.3024, -2.7707,  ..., -3.8861, -3.7892, -3.4819],\n",
      "        [-2.6572, -3.4468, -2.8131,  ..., -3.4086, -3.4014, -2.9299],\n",
      "        [-3.1528, -3.1923, -3.2733,  ..., -4.1034, -4.0151, -3.7415]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '已', '經', '決', '定', '要', '成', '為', '一', '名', '教', '師', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '是', '是', '是', '你', '姆', '的', '。', '。', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6554, -1.0535,  1.2645, -0.8022, -0.0095, -0.0608,  0.0094, -0.5612,\n",
      "         1.0530,  0.6304, -0.1202, -1.8524, -1.4969, -0.0379, -0.9261,  0.7807,\n",
      "        -1.3794, -0.1678, -0.9816,  1.2915,  1.4540, -0.8035,  2.1575,  1.1324,\n",
      "         0.7462,  0.2631,  1.3102,  0.4758,  0.7709, -0.1135, -0.0383, -2.3860],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7157, -0.3004, -0.4244, -0.2919,  2.0665,  0.3829,  0.4439, -1.0826,\n",
      "         0.4832, -1.5758,  1.9774, -0.6708, -0.6678,  0.7320,  0.1121,  0.8498,\n",
      "        -1.7041,  0.3315, -0.6015,  0.7391,  0.1865,  1.3600, -0.5082, -0.1422,\n",
      "         0.5104, -1.4968, -2.8599, -0.9897,  0.0122, -1.4546, -0.0560, -0.3703],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1765.1560, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 272, 301,   5,   2,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 56, 10, 59,  2,  2,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.2238,  1.6898,  1.8313,  ...,  2.8013,  2.7601,  2.7772],\n",
      "        [-6.0922, -6.1099, -5.8485,  ..., -6.9235, -7.2360, -7.1989],\n",
      "        [ 3.4182,  1.5091,  0.5491,  ...,  2.5822,  3.3946,  2.9679],\n",
      "        ...,\n",
      "        [-3.7258, -3.6402, -3.3734,  ..., -3.5699, -3.7157, -3.6730],\n",
      "        [-3.5646, -4.3103, -3.9999,  ..., -3.3339, -3.4894, -3.5804],\n",
      "        [-3.7711, -3.8967, -3.5727,  ..., -4.2555, -4.3165, -4.2389]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '真', '蠢', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '们', '的', '么', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6799, -1.0271,  1.2442, -0.7934, -0.0285, -0.0579,  0.0214, -0.5548,\n",
      "         1.0457,  0.6229, -0.1175, -1.8413, -1.5165, -0.0396, -0.9235,  0.7624,\n",
      "        -1.3663, -0.1581, -0.9654,  1.2720,  1.4477, -0.7975,  2.1516,  1.1275,\n",
      "         0.7170,  0.2682,  1.3062,  0.4744,  0.7719, -0.1301, -0.0310, -2.3790],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7237, -0.3238, -0.4401, -0.2973,  2.0674,  0.3765,  0.4362, -1.0812,\n",
      "         0.4774, -1.5808,  1.9668, -0.6684, -0.6710,  0.7275,  0.1184,  0.8531,\n",
      "        -1.7097,  0.3424, -0.6014,  0.7258,  0.1985,  1.3687, -0.5256, -0.1446,\n",
      "         0.5071, -1.4586, -2.8394, -0.9916,  0.0242, -1.4462, -0.0500, -0.3708],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1489.4667, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 202, 163, 353,  82,  83,  22,   5,   2,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 23, 19, 23, 10,  5,  5,  5,  2,  2,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.9138,  1.3463,  1.2985,  ...,  2.5557,  2.5468,  2.5567],\n",
      "        [-6.1405, -5.5769, -6.8817,  ..., -7.1653, -7.5016, -6.2252],\n",
      "        [ 3.4035,  0.7187,  2.0270,  ...,  2.8950,  3.6316,  2.2612],\n",
      "        ...,\n",
      "        [-3.7449, -3.3093, -3.5950,  ..., -3.6767, -3.8012, -3.5016],\n",
      "        [-3.6549, -4.1543, -4.4695,  ..., -3.5592, -3.5607, -3.2856],\n",
      "        [-3.5275, -3.3575, -3.7964,  ..., -3.9281, -4.1508, -3.6314]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '現', '在', '想', '回', '家', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '我', '不', '的', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6846, -1.0203,  1.2513, -0.7990, -0.0256, -0.0556,  0.0259, -0.5376,\n",
      "         1.0485,  0.6333, -0.1129, -1.8448, -1.5289, -0.0321, -0.9290,  0.7603,\n",
      "        -1.3771, -0.1651, -0.9718,  1.2535,  1.4671, -0.7785,  2.1492,  1.1456,\n",
      "         0.7132,  0.2569,  1.2978,  0.4832,  0.7808, -0.1116, -0.0158, -2.3855],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7294, -0.3404, -0.4694, -0.2936,  2.0524,  0.3859,  0.4314, -1.0972,\n",
      "         0.4600, -1.6027,  1.9400, -0.6514, -0.6817,  0.7188,  0.1100,  0.8434,\n",
      "        -1.7040,  0.3438, -0.6016,  0.7063,  0.2152,  1.3716, -0.5326, -0.1200,\n",
      "         0.5010, -1.4095, -2.8455, -0.9808,  0.0293, -1.4436, -0.0471, -0.3582],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1695.7139, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  352,   29,   30,  193,  393, 1568,    0, 1987,  390,   10,   60,\n",
      "         412,  167,  628,   35,   33,    2,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6, 64,  6, 64, 60, 60, 60, 10,  5, 33, 59, 36, 33,  5,  5, 33,  2,  2,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.9007,  1.8870,  1.8142,  ...,  2.7677,  2.8825,  2.7480],\n",
      "        [-5.3171, -5.9528, -6.6807,  ..., -7.2900, -7.0154, -7.7746],\n",
      "        [ 2.2478,  0.5044,  0.4873,  ...,  3.4277,  2.6601,  3.7390],\n",
      "        ...,\n",
      "        [-3.6537, -3.8980, -3.6533,  ..., -3.9286, -3.9116, -4.0369],\n",
      "        [-3.1661, -4.0452, -4.0410,  ..., -3.6627, -3.5579, -3.7103],\n",
      "        [-3.2953, -3.3530, -3.4553,  ..., -3.6061, -3.4571, -3.8349]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '您', '知', '道', '这', '座', '庙', '<unknown>', '供', '奉', '的', '是', '哪', '个', '神', '吗', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '姆', '你', '姆', '是', '是', '是', '的', '。', '？', '么', '他', '？', '。', '。', '？', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.6972, -1.0048,  1.2343, -0.7912, -0.0363, -0.0454,  0.0369, -0.5083,\n",
      "         1.0511,  0.6306, -0.0901, -1.8403, -1.5540, -0.0197, -0.9211,  0.7375,\n",
      "        -1.3658, -0.1592, -0.9574,  1.2334,  1.4662, -0.7698,  2.1365,  1.1392,\n",
      "         0.6889,  0.2599,  1.2995,  0.4858,  0.7848, -0.1220,  0.0144, -2.3939],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7154, -0.3284, -0.4830, -0.2747,  2.0499,  0.3985,  0.4264, -1.0984,\n",
      "         0.4556, -1.6081,  1.9237, -0.6464, -0.6765,  0.7239,  0.1042,  0.8272,\n",
      "        -1.6884,  0.3235, -0.5852,  0.7212,  0.2098,  1.3580, -0.5107, -0.1023,\n",
      "         0.5268, -1.3853, -2.8380, -0.9814,  0.0220, -1.4471, -0.0474, -0.3615],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1908.5835, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,   97,   98,   63,   64,   32,  596,  104, 1421,  814,  429,\n",
      "          22,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19, 174,  19,  19,  64,  10,  15,   5,   5,   5,   5,   5,   5,   2,\n",
      "          2,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.5809,  1.1001,  1.0847,  ...,  2.5105,  2.6753,  2.5641],\n",
      "        [-5.6356, -5.5411, -6.3491,  ..., -7.8528, -7.4760, -6.9903],\n",
      "        [ 3.2233,  0.6841,  1.9129,  ...,  3.2409,  2.9166,  3.0372],\n",
      "        ...,\n",
      "        [-3.4612, -3.2503, -3.2513,  ..., -4.1279, -3.8641, -3.5665],\n",
      "        [-3.3737, -4.1771, -4.1351,  ..., -3.8906, -3.6361, -3.3899],\n",
      "        [-3.1616, -3.0711, -3.5276,  ..., -3.9522, -3.8206, -3.7113]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '觉', '得', '汤', '姆', '有', '些', '过', '于', '性', '急', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '們', '我', '我', '姆', '的', '一', '。', '。', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-7.2719e-01, -9.8521e-01,  1.2057e+00, -7.8863e-01, -4.8806e-02,\n",
      "        -5.6766e-02,  1.9980e-02, -4.9684e-01,  1.0250e+00,  6.1474e-01,\n",
      "        -6.9501e-02, -1.8182e+00, -1.5614e+00, -1.7569e-02, -9.4259e-01,\n",
      "         7.1199e-01, -1.3567e+00, -1.6532e-01, -9.4493e-01,  1.2292e+00,\n",
      "         1.4678e+00, -7.5874e-01,  2.1419e+00,  1.1170e+00,  6.6419e-01,\n",
      "         2.6991e-01,  1.2809e+00,  4.9131e-01,  7.9088e-01, -1.4457e-01,\n",
      "         1.8874e-03, -2.3755e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7122, -0.3318, -0.4951, -0.2609,  2.0418,  0.4056,  0.4082, -1.1004,\n",
      "         0.4470, -1.6154,  1.9115, -0.6416, -0.6948,  0.7135,  0.1010,  0.8340,\n",
      "        -1.6788,  0.3172, -0.5742,  0.7181,  0.2164,  1.3507, -0.5121, -0.0916,\n",
      "         0.5387, -1.3610, -2.8382, -0.9837,  0.0331, -1.4530, -0.0439, -0.3608],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1739.1946, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  93, 648, 143,  23, 239, 208, 493,  22,   5,   2,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  23,  59,  10,  10,  10,   5,   5,   5,   2,   2,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.5896,  1.9630,  2.7653,  ...,  2.5055,  2.3480,  2.4144],\n",
      "        [-4.5190, -6.1271, -5.4193,  ..., -6.5589, -6.8625, -7.5711],\n",
      "        [ 0.3232,  0.1753, -0.5277,  ...,  2.5300,  3.1722,  3.4555],\n",
      "        ...,\n",
      "        [-3.0751, -3.3597, -3.0237,  ..., -3.5176, -3.6833, -4.0366],\n",
      "        [-2.3568, -3.5514, -2.2914,  ..., -3.1373, -3.3142, -3.5125],\n",
      "        [-3.0001, -3.4620, -3.3966,  ..., -3.5666, -3.6966, -3.9423]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '请', '小', '心', '不', '要', '受', '伤', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '不', '么', '的', '的', '的', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7244, -0.9970,  1.2266, -0.7926, -0.0189, -0.0430,  0.0168, -0.4930,\n",
      "         1.0428,  0.6379, -0.0706, -1.8333, -1.5919, -0.0077, -0.9159,  0.7219,\n",
      "        -1.3726, -0.1561, -0.9605,  1.2337,  1.4657, -0.7528,  2.1206,  1.0941,\n",
      "         0.6469,  0.2746,  1.2850,  0.4993,  0.8101, -0.1458,  0.0288, -2.4001],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7381, -0.3497, -0.4952, -0.2658,  2.0274,  0.4091,  0.3998, -1.0959,\n",
      "         0.4391, -1.6206,  1.9111, -0.6430, -0.7247,  0.7021,  0.1127,  0.8733,\n",
      "        -1.6805,  0.3168, -0.5716,  0.7056,  0.2288,  1.3728, -0.5311, -0.1065,\n",
      "         0.5263, -1.3573, -2.8341, -1.0021,  0.0487, -1.4825, -0.0295, -0.3646],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1749.1583, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   61,  112,  853, 1169,  199,   15,  392,  189,  175, 1421,  177,\n",
      "        1035,  249,   10,  328, 1504,    5,    2,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60,  60,  10,  10,  10, 360,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5,   2,  33,   2,   2,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.2587,  3.0248,  3.4705,  ...,  2.5580,  2.5229,  2.7705],\n",
      "        [-3.8100, -4.8726, -4.9626,  ..., -6.6738, -6.7119, -6.0987],\n",
      "        [-0.8706, -1.9840, -1.8004,  ...,  2.3765,  3.0939,  2.2859],\n",
      "        ...,\n",
      "        [-2.4196, -2.4860, -3.1387,  ..., -3.2186, -3.1823, -3.1222],\n",
      "        [-1.8602, -2.2511, -2.2919,  ..., -3.2910, -3.1764, -2.9060],\n",
      "        [-2.6936, -2.9822, -3.1684,  ..., -3.5702, -3.6335, -3.4735]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '去', '美', '国', '旅', '行', '一', '次', '相', '当', '于', '她', '两', '年', '的', '工', '资', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '是', '的', '的', '的', '個', '。', '。', '。', '。', '。', '。', '。', '。', '<eos>', '？', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-7.4894e-01, -9.8786e-01,  1.2018e+00, -8.0413e-01, -1.1790e-02,\n",
      "        -5.3882e-02,  8.2138e-04, -4.7433e-01,  1.0439e+00,  6.4415e-01,\n",
      "        -6.4643e-02, -1.8233e+00, -1.6052e+00, -1.7841e-03, -9.1585e-01,\n",
      "         7.0714e-01, -1.3743e+00, -1.5541e-01, -9.5419e-01,  1.2454e+00,\n",
      "         1.4862e+00, -7.2335e-01,  2.1252e+00,  1.0777e+00,  6.4180e-01,\n",
      "         2.6943e-01,  1.2721e+00,  5.1785e-01,  8.1544e-01, -1.4682e-01,\n",
      "         3.6817e-02, -2.4010e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7405, -0.3600, -0.4976, -0.2633,  2.0323,  0.4026,  0.3926, -1.0923,\n",
      "         0.4417, -1.6200,  1.9093, -0.6521, -0.7165,  0.7141,  0.1172,  0.8613,\n",
      "        -1.6850,  0.3204, -0.5673,  0.7081,  0.2252,  1.3714, -0.5267, -0.1024,\n",
      "         0.5359, -1.3510, -2.8185, -1.0074,  0.0357, -1.4657, -0.0345, -0.3712],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1690.7053, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  236,   64,   43,   32,   86,  658,   19,  177,   10,  900, 1059,\n",
      "           5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 64, 23, 19, 19, 19, 19, 10, 10,  5,  5,  5,  2, 19,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.4748,  1.2861,  1.4236,  ...,  2.2463,  2.0729,  2.4865],\n",
      "        [-5.8305, -7.0189, -7.0172,  ..., -7.1436, -7.2359, -7.6492],\n",
      "        [ 3.1546,  2.6231,  0.6295,  ...,  3.2790,  2.6566,  2.6807],\n",
      "        ...,\n",
      "        [-3.5355, -3.7823, -3.7457,  ..., -3.7023, -3.7180, -4.0299],\n",
      "        [-3.6065, -4.5321, -4.4492,  ..., -3.5804, -3.9129, -3.7165],\n",
      "        [-3.6219, -4.1036, -3.8161,  ..., -3.8583, -3.8973, -4.0355]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '湯', '姆', '沒', '有', '告', '訴', '我', '她', '的', '名', '字', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '姆', '不', '我', '我', '我', '我', '的', '的', '。', '。', '。', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7789, -0.9616,  1.1780, -0.8199,  0.0055, -0.0628, -0.0080, -0.4629,\n",
      "         1.0439,  0.6340, -0.0447, -1.8079, -1.6245,  0.0049, -0.9239,  0.6839,\n",
      "        -1.3773, -0.1516, -0.9387,  1.2509,  1.5166, -0.7192,  2.1270,  1.0556,\n",
      "         0.6269,  0.2691,  1.2645,  0.5311,  0.8184, -0.1586,  0.0332, -2.3943],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7539, -0.3769, -0.5122, -0.2688,  2.0276,  0.4048,  0.3835, -1.0921,\n",
      "         0.4334, -1.6238,  1.8989, -0.6447, -0.7315,  0.7067,  0.1246,  0.8593,\n",
      "        -1.6980,  0.3326, -0.5764,  0.7067,  0.2363,  1.3807, -0.5417, -0.1056,\n",
      "         0.5255, -1.3367, -2.8070, -1.0053,  0.0490, -1.4575, -0.0195, -0.3667],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1504.3447, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   36,   16, 1865,  282,  239, 1331,  671,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 36,  60,  22, 360, 360,  10,   5,   5,   2,   2,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.5230,  2.0135,  2.1111,  ...,  2.7473,  2.7397,  2.6360],\n",
      "        [-5.1220, -5.8111, -6.5582,  ..., -7.5738, -6.7623, -6.7730],\n",
      "        [ 1.5154, -0.2961, -0.0082,  ...,  3.0193,  2.5394,  2.8038],\n",
      "        ...,\n",
      "        [-2.8337, -3.1113, -2.9872,  ..., -3.4420, -3.1929, -3.2008],\n",
      "        [-2.7849, -3.9391, -3.6742,  ..., -3.5519, -3.4040, -3.4144],\n",
      "        [-3.4218, -3.2166, -3.2998,  ..., -3.7515, -3.3897, -3.4695]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '下', '禮', '拜', '要', '考', '試', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['他', '是', '了', '個', '個', '的', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7814, -0.9568,  1.1679, -0.8216,  0.0192, -0.0684, -0.0027, -0.4701,\n",
      "         1.0439,  0.6379, -0.0462, -1.8055, -1.6222,  0.0040, -0.9295,  0.6849,\n",
      "        -1.3866, -0.1580, -0.9408,  1.2528,  1.5223, -0.7119,  2.1302,  1.0537,\n",
      "         0.6264,  0.2711,  1.2587,  0.5320,  0.8218, -0.1520,  0.0342, -2.3945],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7537, -0.4055, -0.5478, -0.2756,  2.0134,  0.4093,  0.4031, -1.1140,\n",
      "         0.4076, -1.6472,  1.8652, -0.6270, -0.7306,  0.6920,  0.1208,  0.8153,\n",
      "        -1.6960,  0.3436, -0.5853,  0.6874,  0.2583,  1.3887, -0.5610, -0.0779,\n",
      "         0.5027, -1.2998, -2.8035, -0.9701,  0.0723, -1.4234, -0.0123, -0.3448],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1614.0026, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  31, 623, 189, 190, 128,  63,  64,  31, 171,  90, 465, 159, 293,\n",
      "         15, 167, 171, 147, 140,  78,  22, 193, 596,   5,   2,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  23, 266,  19,  19,  19,  19,  19,  19, 163,  19,  19,  19,  10,\n",
      "        167, 171,   5,   5,  19,  19,   5,   5,   5,   2,  19,   2,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.7840,  1.6730,  1.7977,  ...,  2.3035,  2.3514,  2.3801],\n",
      "        [-5.7401, -6.5429, -5.9629,  ..., -7.7154, -8.3200, -8.0488],\n",
      "        [ 2.9756,  0.4846, -1.1062,  ...,  4.3320,  3.9029,  4.0223],\n",
      "        ...,\n",
      "        [-3.0239, -3.0747, -2.5632,  ..., -3.7293, -3.8293, -3.8261],\n",
      "        [-3.3529, -4.2132, -3.3225,  ..., -4.2535, -4.4718, -4.3787],\n",
      "        [-3.1997, -3.4584, -3.5712,  ..., -4.1403, -4.4664, -4.2676]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '没', '法', '相', '信', '，', '汤', '姆', '没', '人', '帮', '助', '自', '己', '一', '个', '人', '就', '做', '到', '了', '这', '些', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '天', '我', '我', '我', '我', '我', '我', '在', '我', '我', '我', '的', '个', '人', '。', '。', '我', '我', '。', '。', '。', '<eos>', '我', '<eos>', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7853, -0.9598,  1.1437, -0.8352,  0.0090, -0.0626,  0.0197, -0.4648,\n",
      "         1.0593,  0.6307, -0.0394, -1.8164, -1.6372,  0.0241, -0.9172,  0.6934,\n",
      "        -1.3737, -0.1491, -0.9389,  1.2359,  1.5365, -0.7207,  2.1253,  1.0787,\n",
      "         0.6350,  0.2493,  1.2471,  0.5279,  0.8225, -0.1329,  0.0562, -2.4019],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 7.4140e-01, -4.0971e-01, -5.7645e-01, -2.6011e-01,  1.9897e+00,\n",
      "         4.3705e-01,  4.2519e-01, -1.1381e+00,  3.7931e-01, -1.6741e+00,\n",
      "         1.8297e+00, -5.9659e-01, -7.3786e-01,  6.7254e-01,  1.0401e-01,\n",
      "         7.7967e-01, -1.6729e+00,  3.2210e-01, -5.7834e-01,  6.8422e-01,\n",
      "         2.7771e-01,  1.3849e+00, -5.5789e-01, -3.6855e-02,  4.8904e-01,\n",
      "        -1.2629e+00, -2.8243e+00, -9.2929e-01,  9.4821e-02, -1.4477e+00,\n",
      "         2.3060e-03, -3.1701e-01], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1454.5902, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  236,   64,  422,  623, 1536,  422,   98,   23,  221,    7,    5,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 36,  64, 163,  36, 167,  10,   5,   5,  10,   5,   5,   2,   2,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.1943,  1.8055,  1.9851,  ...,  2.5343,  2.4674,  2.5677],\n",
      "        [-5.3581, -6.2967, -6.0718,  ..., -6.7256, -6.5392, -6.6389],\n",
      "        [ 1.5934,  1.0308, -0.8224,  ...,  2.9782,  3.3837,  2.1265],\n",
      "        ...,\n",
      "        [-3.0584, -3.2354, -3.3529,  ..., -3.1855, -3.2219, -3.3274],\n",
      "        [-2.9837, -4.0652, -3.9632,  ..., -3.3576, -3.4353, -3.4737],\n",
      "        [-3.5945, -3.6682, -3.2862,  ..., -3.5325, -3.3420, -3.4137]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '湯', '姆', '說', '法', '語', '說', '得', '不', '太', '好', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['他', '姆', '在', '他', '个', '的', '。', '。', '的', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7799, -0.9720,  1.1297, -0.8386,  0.0336, -0.0701, -0.0057, -0.4688,\n",
      "         1.0594,  0.6483, -0.0513, -1.8154, -1.6205,  0.0150, -0.9205,  0.7014,\n",
      "        -1.3794, -0.1638, -0.9518,  1.2531,  1.5313, -0.7126,  2.1280,  1.0835,\n",
      "         0.6472,  0.2451,  1.2365,  0.5215,  0.8173, -0.1139,  0.0526, -2.4042],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 7.5010e-01, -4.2293e-01, -5.7465e-01, -2.5923e-01,  1.9861e+00,\n",
      "         4.2945e-01,  4.3105e-01, -1.1325e+00,  3.7555e-01, -1.6765e+00,\n",
      "         1.8284e+00, -6.0068e-01, -7.3275e-01,  6.7117e-01,  1.0683e-01,\n",
      "         7.7775e-01, -1.6713e+00,  3.3725e-01, -5.8896e-01,  6.7851e-01,\n",
      "         2.8223e-01,  1.3918e+00, -5.6946e-01, -4.6074e-02,  4.8345e-01,\n",
      "        -1.2690e+00, -2.8148e+00, -9.2417e-01,  1.0615e-01, -1.4306e+00,\n",
      "         2.5716e-03, -3.1519e-01], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1700.3173, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  193,  167,  328,  329,   31,   32, 1782, 1783,    5,    2,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60, 171, 329,   5,  10,  22,  10,   5,   2,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.3650,  2.9011,  3.1049,  ...,  2.5009,  2.7050,  2.3854],\n",
      "        [-4.4617, -5.1239, -4.8040,  ..., -7.0496, -6.9405, -6.6254],\n",
      "        [-0.4542, -2.0932, -1.9265,  ...,  2.8113,  2.0555,  3.4691],\n",
      "        ...,\n",
      "        [-2.6795, -2.8377, -2.5107,  ..., -3.6010, -3.5889, -3.4716],\n",
      "        [-2.0167, -2.3254, -1.2956,  ..., -3.4894, -3.3381, -3.3375],\n",
      "        [-2.8681, -2.9900, -3.0253,  ..., -3.3650, -3.3314, -3.2441]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '这', '个', '工', '作', '没', '有', '酬', '劳', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '人', '作', '。', '的', '了', '的', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-7.6950e-01, -9.7792e-01,  1.1260e+00, -8.3117e-01,  3.5704e-02,\n",
      "        -6.2072e-02,  9.9733e-04, -4.6964e-01,  1.0542e+00,  6.4538e-01,\n",
      "        -6.0626e-02, -1.8183e+00, -1.6166e+00,  9.4902e-03, -9.1691e-01,\n",
      "         7.0759e-01, -1.3718e+00, -1.6307e-01, -9.5178e-01,  1.2539e+00,\n",
      "         1.5176e+00, -7.2658e-01,  2.1134e+00,  1.0907e+00,  6.4308e-01,\n",
      "         2.5027e-01,  1.2365e+00,  5.2601e-01,  8.1084e-01, -1.0809e-01,\n",
      "         6.2196e-02, -2.4032e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 7.5921e-01, -4.3006e-01, -5.7270e-01, -2.6427e-01,  1.9885e+00,\n",
      "         4.2378e-01,  4.4005e-01, -1.1296e+00,  3.7352e-01, -1.6801e+00,\n",
      "         1.8281e+00, -6.0335e-01, -7.2709e-01,  6.7385e-01,  1.1086e-01,\n",
      "         7.7702e-01, -1.6661e+00,  3.4451e-01, -5.8859e-01,  6.6463e-01,\n",
      "         2.8644e-01,  1.3930e+00, -5.7753e-01, -4.9161e-02,  4.8180e-01,\n",
      "        -1.2625e+00, -2.8064e+00, -9.2596e-01,  1.1410e-01, -1.4312e+00,\n",
      "         2.1267e-03, -3.1886e-01], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1613.7614, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 236,  64, 946, 375,  22,   5,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  64, 163,  22,  10,   5,   2,   2,   5,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.6234,  1.3782,  1.5330,  ...,  2.0911,  2.2365,  2.1223],\n",
      "        [-5.4769, -6.8870, -6.9297,  ..., -7.0097, -7.5427, -7.3901],\n",
      "        [ 1.7956,  1.3515,  0.0573,  ...,  2.4385,  2.4673,  2.4851],\n",
      "        ...,\n",
      "        [-3.3260, -3.5763, -3.7953,  ..., -3.5959, -3.7215, -3.6262],\n",
      "        [-3.0786, -4.1251, -4.1090,  ..., -3.4842, -3.6551, -3.7238],\n",
      "        [-3.7448, -3.9281, -3.7036,  ..., -3.1425, -3.3153, -3.3236]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '湯', '姆', '變', '胖', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '姆', '在', '了', '的', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.7891, -0.9650,  1.0947, -0.8378,  0.0322, -0.0648, -0.0080, -0.4722,\n",
      "         1.0352,  0.6439, -0.0587, -1.8054, -1.6164,  0.0118, -0.9266,  0.7025,\n",
      "        -1.3683, -0.1526, -0.9482,  1.2681,  1.5209, -0.7070,  2.1205,  1.0729,\n",
      "         0.6127,  0.2603,  1.2308,  0.5350,  0.8282, -0.1131,  0.0404, -2.3963],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7523, -0.4346, -0.5638, -0.2755,  2.0100,  0.4046,  0.4597, -1.1261,\n",
      "         0.3847, -1.6755,  1.8336, -0.6120, -0.6940,  0.7013,  0.1232,  0.7497,\n",
      "        -1.6545,  0.3452, -0.5667,  0.6607,  0.2711,  1.3833, -0.5847, -0.0366,\n",
      "         0.4882, -1.2467, -2.7903, -0.9181,  0.1198, -1.4143, -0.0237, -0.3284],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1391.7766, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,  355,  514,  544,  928,  291,   61, 1425,  199,    5,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  23,  19,  19, 239,  19,  33,   5,  33,   5,   2,   2,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.7408,  1.1712,  0.9372,  ...,  2.4906,  2.4153,  2.2616],\n",
      "        [-6.2721, -7.4518, -8.2065,  ..., -7.8772, -7.1449, -7.4864],\n",
      "        [ 2.8963,  0.7093,  1.0767,  ...,  2.6230,  2.3032,  3.2156],\n",
      "        ...,\n",
      "        [-3.7943, -4.0789, -3.7674,  ..., -4.1441, -3.6246, -3.7510],\n",
      "        [-3.7331, -4.6438, -4.6637,  ..., -3.5727, -3.3052, -3.5347],\n",
      "        [-4.0022, -3.7559, -4.2727,  ..., -3.4504, -3.2476, -3.4853]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '应', '该', '带', '护', '照', '去', '银', '行', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '不', '我', '我', '要', '我', '？', '。', '？', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8103, -0.9527,  1.0631, -0.8445,  0.0423, -0.0614, -0.0204, -0.4686,\n",
      "         1.0385,  0.6606, -0.0590, -1.7979, -1.6341,  0.0100, -0.9255,  0.6994,\n",
      "        -1.3821, -0.1508, -0.9399,  1.2721,  1.5469, -0.6891,  2.1331,  1.0602,\n",
      "         0.6032,  0.2599,  1.2151,  0.5507,  0.8307, -0.1153,  0.0424, -2.3961],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7451, -0.4281, -0.5642, -0.2588,  2.0108,  0.4065,  0.4614, -1.1228,\n",
      "         0.3864, -1.6704,  1.8253, -0.6149, -0.6928,  0.7073,  0.1201,  0.7326,\n",
      "        -1.6400,  0.3469, -0.5670,  0.6717,  0.2692,  1.3677, -0.5722, -0.0235,\n",
      "         0.5058, -1.2470, -2.7859, -0.9055,  0.1154, -1.4121, -0.0346, -0.3272],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1699.8457, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,  398, 1863,  212,  297,    5,    2,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 56, 22, 22, 22,  5,  2, 64, 10, 10,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 1.3283,  1.6943,  1.9723,  ...,  2.9592,  2.9765,  2.7006],\n",
      "        [-5.8587, -5.8108, -7.0325,  ..., -7.8415, -7.8131, -7.0312],\n",
      "        [ 1.8822, -0.6229, -0.4735,  ...,  1.7769,  2.4896,  2.4936],\n",
      "        ...,\n",
      "        [-3.2653, -3.1582, -3.4075,  ..., -3.7597, -3.5197, -3.1443],\n",
      "        [-3.0580, -3.6593, -3.4874,  ..., -3.1294, -3.1854, -2.9333],\n",
      "        [-3.3990, -3.0094, -3.3787,  ..., -3.6309, -3.7523, -3.4526]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '习', '惯', '晚', '睡', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '们', '了', '了', '了', '。', '<eos>', '姆', '的', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8103, -0.9543,  1.0487, -0.8276,  0.0402, -0.0589, -0.0101, -0.4747,\n",
      "         1.0559,  0.6557, -0.0518, -1.7969, -1.6295,  0.0207, -0.9187,  0.7087,\n",
      "        -1.3625, -0.1405, -0.9427,  1.2685,  1.5559, -0.6997,  2.1240,  1.0650,\n",
      "         0.6098,  0.2583,  1.2155,  0.5405,  0.8272, -0.1073,  0.0457, -2.3966],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7366, -0.4212, -0.5627, -0.2373,  2.0162,  0.4025,  0.4509, -1.1189,\n",
      "         0.3943, -1.6529,  1.8224, -0.6234, -0.6917,  0.7196,  0.1121,  0.7154,\n",
      "        -1.6328,  0.3536, -0.5813,  0.6977,  0.2578,  1.3444, -0.5569, -0.0093,\n",
      "         0.5277, -1.2688, -2.7786, -0.8923,  0.1021, -1.3870, -0.0465, -0.3257],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1418.3997, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   36,  586,  149,   41,   22,  271, 1390,  834,  168,    5,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 36, 163, 122, 163,  22,   5, 360,   5,   5,   5,   2,   2,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.5271,  2.0658,  2.4549,  ...,  2.5637,  2.2662,  2.5513],\n",
      "        [-5.7222, -6.4535, -5.2426,  ..., -7.4137, -6.8261, -7.3280],\n",
      "        [ 1.9663, -0.0683, -3.1660,  ...,  2.1557,  3.3696,  2.5947],\n",
      "        ...,\n",
      "        [-3.2944, -3.4335, -2.5882,  ..., -3.8599, -3.6426, -3.8269],\n",
      "        [-3.0352, -3.8425, -1.9994,  ..., -3.6543, -3.5842, -3.6217],\n",
      "        [-3.8187, -3.4367, -2.6971,  ..., -3.1073, -2.9782, -3.1878]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '被', '趕', '出', '了', '這', '棟', '房', '子', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['他', '在', '欢', '在', '了', '。', '個', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8358, -0.9298,  1.0254, -0.8277,  0.0365, -0.0602, -0.0106, -0.4886,\n",
      "         1.0477,  0.6461, -0.0451, -1.7788, -1.6454,  0.0128, -0.9237,  0.7051,\n",
      "        -1.3715, -0.1356, -0.9234,  1.2703,  1.5646, -0.6795,  2.1295,  1.0524,\n",
      "         0.5891,  0.2660,  1.2137,  0.5412,  0.8469, -0.1196,  0.0366, -2.3918],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7348, -0.4278, -0.5689, -0.2349,  2.0120,  0.4033,  0.4747, -1.1282,\n",
      "         0.3871, -1.6526,  1.8192, -0.6221, -0.6731,  0.7330,  0.1132,  0.6908,\n",
      "        -1.6201,  0.3549, -0.5848,  0.7039,  0.2472,  1.3423, -0.5648,  0.0030,\n",
      "         0.5247, -1.2475, -2.7777, -0.8657,  0.1135, -1.3783, -0.0599, -0.3184],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1491.7396, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  228,  580,    6,  353,  437,   98, 1375,   15,   68,  147,  778,\n",
      "         551,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6, 266,   6,  10, 163,   6,  19,   5, 167,   5,   5,  33,   5,   2,\n",
      "         19,   5,  33,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.4801,  1.9934,  1.1960,  ...,  2.5019,  2.4137,  2.0702],\n",
      "        [-5.9655, -6.1704, -8.1631,  ..., -7.6124, -8.4822, -7.8099],\n",
      "        [ 0.6078, -2.0498,  0.4350,  ...,  2.2256,  3.1062,  3.2544],\n",
      "        ...,\n",
      "        [-3.7234, -3.5966, -3.8229,  ..., -4.1317, -3.9231, -3.9251],\n",
      "        [-3.1982, -3.0876, -4.4491,  ..., -3.4328, -3.5709, -3.8627],\n",
      "        [-3.6919, -3.3694, -4.5960,  ..., -3.4256, -3.8252, -3.3761]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '如', '果', '你', '想', '活', '得', '久', '一', '点', '就', '戒', '烟', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '天', '你', '的', '在', '你', '我', '。', '个', '。', '。', '？', '。', '<eos>', '我', '。', '？', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8196, -0.9402,  1.0318, -0.8185,  0.0169, -0.0554,  0.0024, -0.4940,\n",
      "         1.0608,  0.6453, -0.0458, -1.7912, -1.6484,  0.0277, -0.9128,  0.7152,\n",
      "        -1.3482, -0.1379, -0.9334,  1.2632,  1.5458, -0.6947,  2.1248,  1.0618,\n",
      "         0.6044,  0.2460,  1.2058,  0.5197,  0.8553, -0.1066,  0.0503, -2.4006],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7535, -0.4576, -0.5691, -0.2500,  2.0143,  0.3913,  0.4902, -1.1230,\n",
      "         0.3819, -1.6605,  1.8219, -0.6181, -0.6639,  0.7474,  0.1307,  0.6936,\n",
      "        -1.6141,  0.3686, -0.5720,  0.6816,  0.2522,  1.3572, -0.5896, -0.0043,\n",
      "         0.5076, -1.2257, -2.7647, -0.8616,  0.1399, -1.3832, -0.0660, -0.3239],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1428.8552, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  190,   15,  690,    7,  128,   36,  147,  133,  116, 1109,   22,\n",
      "           5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  36, 167, 171,  10,  19,  10,  32, 177,  10,   5,   5,   2,   2,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.3707,  2.7379,  3.1841,  ...,  2.9557,  3.0784,  3.1009],\n",
      "        [-5.0130, -7.1927, -6.6864,  ..., -7.1720, -7.4546, -7.5551],\n",
      "        [ 0.0555,  1.1876, -1.4026,  ...,  2.8384,  2.0309,  1.9056],\n",
      "        ...,\n",
      "        [-2.9086, -3.4733, -3.4498,  ..., -3.5371, -3.4624, -3.3180],\n",
      "        [-2.3874, -3.3293, -2.8973,  ..., -3.2965, -3.3195, -3.1782],\n",
      "        [-3.1851, -3.7075, -3.4079,  ..., -2.9869, -3.2406, -3.3512]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '信', '一', '写', '好', '，', '他', '就', '把', '它', '寄', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '他', '个', '人', '的', '我', '的', '有', '她', '的', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8230, -0.9329,  1.0316, -0.8176,  0.0226, -0.0679,  0.0073, -0.5093,\n",
      "         1.0487,  0.6283, -0.0544, -1.7802, -1.6340,  0.0173, -0.9205,  0.7271,\n",
      "        -1.3301, -0.1300, -0.9205,  1.2675,  1.5357, -0.6896,  2.1126,  1.0774,\n",
      "         0.5950,  0.2492,  1.2127,  0.5143,  0.8478, -0.1028,  0.0379, -2.3819],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7608, -0.4649, -0.5649, -0.2550,  2.0223,  0.3772,  0.4872, -1.1117,\n",
      "         0.3878, -1.6495,  1.8278, -0.6299, -0.6534,  0.7550,  0.1419,  0.6864,\n",
      "        -1.6206,  0.3821, -0.5732,  0.6832,  0.2527,  1.3514, -0.5981, -0.0046,\n",
      "         0.5085, -1.2230, -2.7479, -0.8681,  0.1432, -1.3682, -0.0704, -0.3311],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1470.3767, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  214,  591,  410, 1746,  168,  170,  177,   99, 1512,   96,    5,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([177, 360, 188, 171, 163, 163, 163,  10,  10,   5,   5,   2,   2,   2,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.0090,  2.7492,  2.9999,  ...,  2.9692,  2.6683,  2.7204],\n",
      "        [-5.3191, -4.3120, -4.5706,  ..., -7.7200, -6.2366, -7.4704],\n",
      "        [ 0.0954, -4.1716, -4.2612,  ...,  2.5181,  4.0429,  2.2334],\n",
      "        ...,\n",
      "        [-3.0767, -2.6343, -2.4582,  ..., -3.4068, -2.9739, -3.7233],\n",
      "        [-2.4395, -1.7683, -1.3000,  ..., -3.2731, -2.8129, -3.6468],\n",
      "        [-3.1856, -2.1862, -2.7212,  ..., -3.1775, -2.4447, -2.9050]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '那', '条', '新', '裙', '子', '让', '她', '很', '满', '意', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['她', '個', 'm', '人', '在', '在', '在', '的', '的', '。', '。', '<eos>', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8306, -0.9298,  1.0161, -0.8187,  0.0206, -0.0497,  0.0031, -0.4893,\n",
      "         1.0541,  0.6451, -0.0370, -1.7840, -1.6578,  0.0271, -0.9026,  0.7224,\n",
      "        -1.3299, -0.1291, -0.9196,  1.2685,  1.5419, -0.6867,  2.1160,  1.0619,\n",
      "         0.5868,  0.2500,  1.2109,  0.5292,  0.8702, -0.1125,  0.0467, -2.3920],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7585, -0.4817, -0.5829, -0.2494,  2.0023,  0.3916,  0.4773, -1.1274,\n",
      "         0.3713, -1.6690,  1.8072, -0.6087, -0.6743,  0.7359,  0.1259,  0.6825,\n",
      "        -1.6073,  0.3772, -0.5624,  0.6625,  0.2714,  1.3531, -0.6034,  0.0113,\n",
      "         0.5000, -1.2146, -2.7603, -0.8602,  0.1636, -1.3899, -0.0536, -0.3179],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1449.5332, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  229,   44, 1151,  304,  101,  163,  625,  909,  255,   68,  299,\n",
      "         408,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193, 329, 163,  10,  60, 163,  15,  22,  10, 164,   5,   5,   5,   2,\n",
      "         19,  10,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 3.3756,  3.3204,  3.6049,  ...,  2.8384,  2.9861,  2.8571],\n",
      "        [-4.6227, -4.2192, -5.7786,  ..., -6.5692, -7.8205, -8.1538],\n",
      "        [-2.2583, -0.8537, -1.9919,  ...,  1.4170,  2.4965,  3.0589],\n",
      "        ...,\n",
      "        [-2.6572, -2.0159, -2.7628,  ..., -2.9891, -3.1713, -3.3512],\n",
      "        [-1.8500, -0.6688, -2.4739,  ..., -3.1575, -3.4165, -3.6266],\n",
      "        [-2.7156, -1.7992, -2.9938,  ..., -2.5160, -3.2351, -3.4001]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '此', '事', '故', '发', '生', '在', '周', '日', '3', '点', '左', '右', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '作', '在', '的', '是', '在', '一', '了', '的', '裡', '。', '。', '。', '<eos>', '我', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.2519e-01, -9.3552e-01,  9.9429e-01, -8.1095e-01,  2.1289e-02,\n",
      "        -4.0086e-02, -1.2823e-03, -4.8558e-01,  1.0619e+00,  6.5623e-01,\n",
      "        -4.3934e-02, -1.7881e+00, -1.6552e+00,  3.0231e-02, -8.9239e-01,\n",
      "         7.2298e-01, -1.3170e+00, -1.3928e-01, -9.2779e-01,  1.2668e+00,\n",
      "         1.5471e+00, -6.8346e-01,  2.1201e+00,  1.0669e+00,  5.9322e-01,\n",
      "         2.4485e-01,  1.2002e+00,  5.3628e-01,  8.7655e-01, -9.6414e-02,\n",
      "         6.6953e-02, -2.4009e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7667, -0.4995, -0.5823, -0.2591,  1.9996,  0.3902,  0.5121, -1.1278,\n",
      "         0.3634, -1.6765,  1.8027, -0.5979, -0.6686,  0.7490,  0.1356,  0.6633,\n",
      "        -1.5802,  0.3819, -0.5443,  0.6559,  0.2728,  1.3585, -0.6200,  0.0261,\n",
      "         0.4882, -1.1925, -2.7531, -0.8339,  0.1919, -1.4038, -0.0664, -0.3184],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1449.5114, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   36,  174,  126,  648, 2218,  278,  231,   61,   22,    5,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 36, 174, 163,  36,  22,  10,  22,  36,  22,   5,   2,   2,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.7798,  2.5261,  2.6936,  ...,  3.2142,  2.7134,  2.7732],\n",
      "        [-5.6196, -5.8160, -6.8719,  ..., -8.4584, -7.0166, -7.2486],\n",
      "        [ 1.5182, -1.3901, -1.0592,  ...,  2.7326,  4.2159,  2.4880],\n",
      "        ...,\n",
      "        [-2.9598, -2.9497, -3.1910,  ..., -3.5522, -3.1855, -3.1692],\n",
      "        [-2.9378, -3.4773, -3.5200,  ..., -3.7221, -3.5474, -3.6308],\n",
      "        [-3.8103, -2.9950, -3.7252,  ..., -3.5991, -3.0202, -2.9461]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '們', '往', '小', '鎮', '方', '向', '去', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['他', '們', '在', '他', '了', '的', '了', '他', '了', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.3303e-01, -9.2940e-01,  9.9465e-01, -8.0578e-01,  2.6060e-02,\n",
      "        -3.9867e-02,  1.4414e-03, -4.8400e-01,  1.0589e+00,  6.4980e-01,\n",
      "        -4.4060e-02, -1.7797e+00, -1.6563e+00,  3.5142e-02, -8.9255e-01,\n",
      "         7.2014e-01, -1.3144e+00, -1.2894e-01, -9.1657e-01,  1.2912e+00,\n",
      "         1.5460e+00, -6.9019e-01,  2.1158e+00,  1.0536e+00,  5.9075e-01,\n",
      "         2.5103e-01,  1.2091e+00,  5.4311e-01,  8.9273e-01, -1.0785e-01,\n",
      "         5.7723e-02, -2.3958e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7669, -0.5050, -0.5705, -0.2610,  2.0102,  0.3848,  0.5391, -1.1160,\n",
      "         0.3697, -1.6716,  1.8077, -0.5995, -0.6531,  0.7729,  0.1442,  0.6504,\n",
      "        -1.5467,  0.3841, -0.5148,  0.6640,  0.2584,  1.3431, -0.6265,  0.0354,\n",
      "         0.4942, -1.1867, -2.7434, -0.8156,  0.2081, -1.4223, -0.0921, -0.3305],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1683.3757, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,  479, 1617,  193,   59,  169,  618,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  23,  30, 163,  60,  22,   5,   5,   2,  19,  10,  10,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.5518,  1.1607,  1.3785,  ...,  2.8840,  2.4162,  2.4496],\n",
      "        [-6.2329, -6.9213, -7.4491,  ..., -8.5050, -8.3687, -7.7211],\n",
      "        [ 1.9715,  0.7861, -0.5445,  ...,  2.2321,  4.4659,  3.5172],\n",
      "        ...,\n",
      "        [-3.0278, -3.3613, -3.0474,  ..., -3.9879, -3.3868, -3.7305],\n",
      "        [-3.7076, -4.6070, -4.1643,  ..., -3.5022, -3.2254, -3.7121],\n",
      "        [-3.5655, -3.4636, -3.8291,  ..., -3.4795, -3.4137, -2.9082]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '从', '未', '这', '么', '高', '兴', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '道', '在', '是', '了', '。', '。', '<eos>', '我', '的', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8377, -0.9335,  1.0055, -0.8106,  0.0343, -0.0531, -0.0040, -0.4904,\n",
      "         1.0514,  0.6622, -0.0655, -1.7766, -1.6566,  0.0371, -0.8939,  0.7255,\n",
      "        -1.3176, -0.1295, -0.9108,  1.2983,  1.5513, -0.6668,  2.1306,  1.0750,\n",
      "         0.5946,  0.2417,  1.2098,  0.5442,  0.9098, -0.1002,  0.0486, -2.3879],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7727, -0.5217, -0.5765, -0.2583,  2.0095,  0.3820,  0.5451, -1.1140,\n",
      "         0.3680, -1.6793,  1.7961, -0.6018, -0.6502,  0.7772,  0.1486,  0.6332,\n",
      "        -1.5384,  0.3906, -0.5107,  0.6588,  0.2614,  1.3496, -0.6318,  0.0483,\n",
      "         0.4933, -1.1693, -2.7248, -0.8051,  0.2204, -1.4218, -0.0955, -0.3300],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1585.8048, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([18, 30]) tensor([   3,   19,   15, 1070,   57,  352, 1612, 1613,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([18, 2643, 29]) tensor([ 19,  23, 122,   6,   6,  10,  22,   5,   2,  19,  10,   5,  10,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.5682,  1.0613,  1.3039,  ...,  2.3069,  2.1785,  2.1630],\n",
      "        [-6.9529, -7.5181, -6.3853,  ..., -8.7009, -8.3934, -8.2954],\n",
      "        [ 2.2729,  0.3164, -1.6701,  ...,  3.3690,  3.2101,  3.2779],\n",
      "        ...,\n",
      "        [-3.7063, -3.8310, -3.4173,  ..., -4.0423, -3.9762, -3.8899],\n",
      "        [-3.9479, -4.8844, -3.2266,  ..., -4.0811, -4.1344, -4.0877],\n",
      "        [-4.0409, -3.8319, -3.2465,  ..., -3.5853, -3.4240, -3.4800]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '一', '直', '为', '您', '骄', '傲', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '欢', '你', '你', '的', '了', '。', '<eos>', '我', '的', '。', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8491, -0.9244,  1.0021, -0.8014,  0.0185, -0.0675, -0.0030, -0.4991,\n",
      "         1.0467,  0.6468, -0.0686, -1.7640, -1.6583,  0.0285, -0.9018,  0.7247,\n",
      "        -1.3123, -0.1368, -0.9067,  1.2985,  1.5527, -0.6552,  2.1395,  1.0725,\n",
      "         0.5960,  0.2468,  1.2024,  0.5448,  0.9112, -0.1011,  0.0391, -2.3826],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7921, -0.5324, -0.5804, -0.2649,  2.0090,  0.3734,  0.5502, -1.1025,\n",
      "         0.3719, -1.6654,  1.7966, -0.6063, -0.6548,  0.7789,  0.1630,  0.6426,\n",
      "        -1.5460,  0.4077, -0.5229,  0.6583,  0.2732,  1.3616, -0.6452,  0.0477,\n",
      "         0.4928, -1.1643, -2.7105, -0.8125,  0.2315, -1.4213, -0.0920, -0.3348],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(878.5306, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6,  47, 723, 567, 252,  33,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  64,  58,  35, 252,  33,   2, 252,  33,  33,  33,  33,  10,  35,\n",
      "         10,  33,   5,  33,  33,  10,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.6711,  1.1953,  1.3902,  ...,  2.2187,  2.2260,  2.0070],\n",
      "        [-5.0459, -7.6703, -9.1934,  ..., -8.5987, -9.3547, -8.3876],\n",
      "        [ 2.2257,  1.1101,  0.2083,  ...,  2.6762,  3.2152,  3.4396],\n",
      "        ...,\n",
      "        [-3.4836, -4.2750, -4.3076,  ..., -4.1445, -4.5905, -4.0025],\n",
      "        [-3.3431, -4.7404, -4.7405,  ..., -4.1799, -4.4070, -4.1857],\n",
      "        [-3.9293, -3.9958, -4.4981,  ..., -3.2958, -3.5764, -3.2540]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '起', '床', '早', '嗎', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '姆', '什', '吗', '嗎', '？', '<eos>', '嗎', '？', '？', '？', '？', '的', '吗', '的', '？', '。', '？', '？', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8554, -0.9246,  1.0040, -0.7960,  0.0202, -0.0702,  0.0067, -0.5000,\n",
      "         1.0485,  0.6315, -0.0624, -1.7613, -1.6656,  0.0207, -0.8974,  0.7258,\n",
      "        -1.3041, -0.1332, -0.8968,  1.2929,  1.5470, -0.6661,  2.1221,  1.0680,\n",
      "         0.6010,  0.2389,  1.2044,  0.5392,  0.9105, -0.0996,  0.0431, -2.3764],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.8044, -0.5348, -0.5648, -0.2656,  2.0260,  0.3571,  0.5549, -1.0773,\n",
      "         0.3911, -1.6473,  1.8089, -0.6218, -0.6398,  0.8006,  0.1849,  0.6455,\n",
      "        -1.5440,  0.4247, -0.5179,  0.6631,  0.2701,  1.3670, -0.6523,  0.0421,\n",
      "         0.5074, -1.1584, -2.6837, -0.8280,  0.2330, -1.4170, -0.1095, -0.3559],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1705.8503, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  239, 1196,  716, 1868,  270,  252,  314,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  58,  33,  33,  60,  33,  33,   2,   2,  10,  33,   5,  10,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.5711,  2.8580,  3.2611,  ...,  2.2356,  2.1255,  1.9380],\n",
      "        [-5.3478, -7.6294, -8.8802,  ..., -8.0315, -6.8802, -6.1371],\n",
      "        [-0.7916, -0.6714,  1.5301,  ...,  3.1188,  3.5761,  4.0284],\n",
      "        ...,\n",
      "        [-3.4101, -3.7961, -4.5477,  ..., -3.9343, -3.6192, -3.2485],\n",
      "        [-2.4971, -3.2107, -3.3508,  ..., -4.1745, -3.7824, -3.2824],\n",
      "        [-2.7755, -3.1228, -3.5551,  ..., -2.9053, -2.3408, -2.0560]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '要', '收', '服', '務', '費', '嗎', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '什', '？', '？', '是', '？', '？', '<eos>', '<eos>', '的', '？', '。', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8610, -0.9275,  1.0064, -0.7820,  0.0238, -0.0617, -0.0078, -0.5010,\n",
      "         1.0477,  0.6236, -0.0652, -1.7552, -1.6562,  0.0169, -0.8971,  0.7304,\n",
      "        -1.2880, -0.1226, -0.9022,  1.3060,  1.5433, -0.6795,  2.1140,  1.0575,\n",
      "         0.6033,  0.2405,  1.2019,  0.5231,  0.9274, -0.1012,  0.0349, -2.3747],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7873, -0.5231, -0.5644, -0.2499,  2.0277,  0.3626,  0.5463, -1.0800,\n",
      "         0.3928, -1.6459,  1.8020, -0.6216, -0.6361,  0.8018,  0.1751,  0.6197,\n",
      "        -1.5359,  0.4184, -0.5077,  0.6698,  0.2721,  1.3428, -0.6360,  0.0592,\n",
      "         0.5242, -1.1621, -2.6813, -0.8259,  0.2298, -1.4202, -0.1145, -0.3528],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1418.6500, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 222,   6,  31, 623, 209, 177, 489, 490,   5,   2,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  23,  22,  23, 163,  10,  30,  10,  59,   5,   2,  19,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.7376,  1.3895,  1.3039,  ...,  2.2749,  2.3819,  2.2754],\n",
      "        [-6.8389, -7.1949, -7.8557,  ..., -7.5116, -9.0264, -8.7714],\n",
      "        [ 2.1635,  0.0165,  0.0268,  ...,  1.9476,  3.5520,  3.6274],\n",
      "        ...,\n",
      "        [-3.3535, -3.3223, -3.1751,  ..., -3.2569, -3.8768, -3.8162],\n",
      "        [-3.9021, -4.6414, -4.1283,  ..., -2.8599, -4.1236, -4.1371],\n",
      "        [-4.0596, -3.5743, -3.9847,  ..., -2.7550, -3.4583, -3.2501]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '怕', '你', '没', '法', '跟', '她', '结', '婚', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '了', '不', '在', '的', '道', '的', '么', '。', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8636, -0.9236,  0.9962, -0.7693,  0.0294, -0.0521, -0.0074, -0.5202,\n",
      "         1.0484,  0.6243, -0.0779, -1.7449, -1.6403,  0.0288, -0.9014,  0.7481,\n",
      "        -1.2862, -0.1275, -0.8955,  1.3106,  1.5488, -0.6708,  2.1270,  1.0712,\n",
      "         0.6008,  0.2452,  1.2046,  0.5119,  0.9551, -0.0946,  0.0230, -2.3738],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7851, -0.5356, -0.5645, -0.2438,  2.0325,  0.3564,  0.5514, -1.0762,\n",
      "         0.3949, -1.6397,  1.8013, -0.6332, -0.6258,  0.8158,  0.1743,  0.6058,\n",
      "        -1.5323,  0.4292, -0.5050,  0.6786,  0.2592,  1.3327, -0.6374,  0.0646,\n",
      "         0.5314, -1.1596, -2.6668, -0.8183,  0.2326, -1.4076, -0.1261, -0.3542],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1347.8245, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,  683,  684,  318,  144, 1375,   33,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6, 23, 98, 58,  6, 58, 33,  2, 64, 10, 33, 33, 33, 33, 33, 33, 33, 33,\n",
      "        33, 33, 33, 10, 33,  5, 33,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.8876,  1.2841,  1.7285,  ...,  2.3675,  2.3312,  2.0916],\n",
      "        [-5.5756, -7.3755, -7.7478,  ..., -8.5141, -9.8275, -8.8342],\n",
      "        [ 1.6018,  0.8109, -1.3306,  ...,  2.0657,  3.8751,  3.6196],\n",
      "        ...,\n",
      "        [-3.2295, -3.8393, -3.4794,  ..., -3.6827, -4.0060, -3.8358],\n",
      "        [-3.3833, -4.7572, -3.3900,  ..., -3.5784, -4.3121, -4.3620],\n",
      "        [-3.9453, -4.0246, -3.6480,  ..., -3.2400, -3.9275, -3.5465]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '准', '备', '待', '多', '久', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '不', '得', '什', '你', '什', '？', '<eos>', '姆', '的', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '？', '的', '？', '。', '？', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8482, -0.9383,  1.0022, -0.7612,  0.0348, -0.0368, -0.0072, -0.5258,\n",
      "         1.0521,  0.6419, -0.0945, -1.7570, -1.6350,  0.0405, -0.8983,  0.7572,\n",
      "        -1.3030, -0.1396, -0.9055,  1.3057,  1.5528, -0.6573,  2.1441,  1.0952,\n",
      "         0.6029,  0.2332,  1.1851,  0.5134,  0.9552, -0.0769,  0.0344, -2.3851],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7745, -0.5443, -0.5750, -0.2363,  2.0244,  0.3602,  0.5495, -1.0879,\n",
      "         0.3821, -1.6487,  1.7912, -0.6237, -0.6269,  0.8102,  0.1637,  0.5783,\n",
      "        -1.5322,  0.4345, -0.5034,  0.6758,  0.2634,  1.3222, -0.6320,  0.0862,\n",
      "         0.5279, -1.1554, -2.6664, -0.7980,  0.2388, -1.3953, -0.1244, -0.3379],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1587.6035, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  439,  426,   19,   24, 1165,  134,  152,  153,  280,  127,   61,\n",
      "         297,   15,   97,    5,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19, 174,  19, 174, 163,  22,  22,  10,  22, 163,  32,  22,   5,   5,\n",
      "          5,   2,  19,  10,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.2790,  1.8906,  1.5620,  ...,  2.9356,  2.8955,  2.5421],\n",
      "        [-6.2065, -7.0343, -8.2184,  ..., -8.0353, -8.3493, -8.6971],\n",
      "        [ 1.4057, -0.6564, -0.2299,  ...,  1.8650,  2.8324,  4.0348],\n",
      "        ...,\n",
      "        [-2.5454, -2.6757, -2.4616,  ..., -2.6883, -2.8648, -3.3329],\n",
      "        [-3.3953, -4.0482, -4.2392,  ..., -3.0730, -3.4505, -4.1256],\n",
      "        [-3.4158, -3.0348, -3.9423,  ..., -2.9195, -3.0443, -3.2248]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '也', '许', '我', '会', '马', '上', '放', '弃', '然', '后', '去', '睡', '一', '觉', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '們', '我', '們', '在', '了', '了', '的', '了', '在', '有', '了', '。', '。', '。', '<eos>', '我', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8398, -0.9419,  1.0298, -0.7539,  0.0519, -0.0332, -0.0133, -0.5053,\n",
      "         1.0472,  0.6443, -0.0902, -1.7569, -1.6295,  0.0424, -0.9029,  0.7542,\n",
      "        -1.2967, -0.1410, -0.9006,  1.3183,  1.5484, -0.6618,  2.1319,  1.0904,\n",
      "         0.6004,  0.2362,  1.1904,  0.5168,  0.9519, -0.0831,  0.0371, -2.3843],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7812, -0.5573, -0.5681, -0.2499,  2.0325,  0.3475,  0.5529, -1.0768,\n",
      "         0.3860, -1.6429,  1.7990, -0.6298, -0.6216,  0.8224,  0.1749,  0.5769,\n",
      "        -1.5253,  0.4456, -0.4983,  0.6729,  0.2545,  1.3259, -0.6442,  0.0772,\n",
      "         0.5250, -1.1518, -2.6511, -0.7994,  0.2498, -1.3942, -0.1328, -0.3483],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1449.2966, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 193,  15, 392,  23,  15, 331,   5,   2,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60,  60, 171,  60, 360,   5,   2,  19,  10,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.3499,  2.3371,  2.3249,  ...,  2.1340,  2.1791,  2.4944],\n",
      "        [-6.4543, -7.1845, -6.6502,  ..., -8.4726, -8.0615, -8.1279],\n",
      "        [-0.6154, -2.2975, -3.1642,  ...,  3.4344,  3.1100,  1.7902],\n",
      "        ...,\n",
      "        [-3.2106, -3.5298, -3.0902,  ..., -3.8099, -3.6923, -3.7454],\n",
      "        [-3.2107, -3.3978, -2.7684,  ..., -4.3748, -4.2701, -3.6258],\n",
      "        [-3.6459, -3.4952, -3.1536,  ..., -3.2792, -3.0899, -3.1184]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '这', '一', '次', '不', '一', '样', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '是', '人', '是', '個', '。', '<eos>', '我', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8508, -0.9324,  1.0126, -0.7578,  0.0468, -0.0300, -0.0317, -0.4737,\n",
      "         1.0508,  0.6475, -0.0751, -1.7535, -1.6298,  0.0323, -0.9036,  0.7391,\n",
      "        -1.2918, -0.1359, -0.8993,  1.3103,  1.5731, -0.6560,  2.1268,  1.0769,\n",
      "         0.5989,  0.2431,  1.1806,  0.5348,  0.9482, -0.0899,  0.0459, -2.3818],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7800, -0.5770, -0.5785, -0.2545,  2.0282,  0.3536,  0.5532, -1.0896,\n",
      "         0.3712, -1.6618,  1.7854, -0.6145, -0.6303,  0.8162,  0.1697,  0.5584,\n",
      "        -1.5167,  0.4478, -0.4928,  0.6560,  0.2641,  1.3350, -0.6504,  0.0889,\n",
      "         0.5127, -1.1366, -2.6458, -0.7893,  0.2642, -1.3862, -0.1349, -0.3400],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1545.5186, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 236,  64,  29,  30,  19, 163, 729, 458, 730,  11, 466,   5,   2,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 63,  64,  23,  30,  19,  10,  15, 122, 168,   5,   5,   5,   2,  19,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.8848,  1.3433,  1.5733,  ...,  2.5082,  2.4669,  2.2024],\n",
      "        [-5.9352, -7.2039, -7.7087,  ..., -9.2050, -8.6016, -8.2192],\n",
      "        [ 1.9586,  2.0623, -0.4091,  ...,  2.4182,  2.3513,  3.2656],\n",
      "        ...,\n",
      "        [-2.5885, -2.7264, -2.8408,  ..., -3.7351, -3.4751, -3.3888],\n",
      "        [-3.5274, -4.3008, -4.5751,  ..., -4.0556, -3.6637, -3.8356],\n",
      "        [-4.0333, -3.9260, -3.7247,  ..., -3.3507, -3.1851, -3.0918]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '湯', '姆', '知', '道', '我', '在', '波', '士', '頓', '住', '過', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '不', '道', '我', '的', '一', '欢', '子', '。', '。', '。', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8576, -0.9251,  1.0213, -0.7798,  0.0355, -0.0425, -0.0248, -0.4614,\n",
      "         1.0565,  0.6335, -0.0693, -1.7463, -1.6432,  0.0255, -0.8943,  0.7375,\n",
      "        -1.2820, -0.1408, -0.8906,  1.3102,  1.5656, -0.6546,  2.1143,  1.0680,\n",
      "         0.6210,  0.2340,  1.1847,  0.5262,  0.9399, -0.0816,  0.0480, -2.3728],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7890, -0.5925, -0.5766, -0.2655,  2.0281,  0.3486,  0.5686, -1.0869,\n",
      "         0.3648, -1.6638,  1.7837, -0.6076, -0.6297,  0.8245,  0.1779,  0.5551,\n",
      "        -1.5019,  0.4569, -0.4852,  0.6469,  0.2647,  1.3392, -0.6671,  0.0879,\n",
      "         0.5031, -1.1279, -2.6370, -0.7756,  0.2884, -1.3938, -0.1407, -0.3411],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1374.4399, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   63,   64,  239,    0, 2111,   19,    5,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 63,  64,  23,  19, 201,  19,  10,   2,  19,  10,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   2,\n",
      "          5], device='cuda:0') tensor([[ 0.2227,  0.8124,  0.9589,  ...,  2.0602,  0.8076,  1.4756],\n",
      "        [-6.5407, -7.7637, -9.0565,  ..., -8.9468, -5.6978, -5.4912],\n",
      "        [ 2.1599,  1.9043,  1.2561,  ...,  2.4800, 10.2639,  2.7898],\n",
      "        ...,\n",
      "        [-3.2340, -3.4413, -3.7848,  ..., -3.7517, -2.7459, -2.9434],\n",
      "        [-4.0718, -4.9271, -5.1811,  ..., -3.8557, -3.2790, -2.9872],\n",
      "        [-4.3125, -4.2543, -4.4202,  ..., -3.3851, -2.2738, -1.9724]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '汤', '姆', '要', '<unknown>', '罚', '我', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '不', '我', '话', '我', '的', '<eos>', '我', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '<eos>', '。']\n",
      "x embedding 0 tensor([-0.8631, -0.9236,  1.0116, -0.7785,  0.0137, -0.0585, -0.0213, -0.4588,\n",
      "         1.0579,  0.6179, -0.0643, -1.7444, -1.6399,  0.0200, -0.8995,  0.7425,\n",
      "        -1.2733, -0.1463, -0.8949,  1.3135,  1.5657, -0.6634,  2.1024,  1.0753,\n",
      "         0.6332,  0.2336,  1.1760,  0.5117,  0.9406, -0.0816,  0.0399, -2.3631],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7921, -0.6065, -0.5730, -0.2660,  2.0269,  0.3461,  0.5869, -1.0835,\n",
      "         0.3648, -1.6660,  1.7843, -0.6050, -0.6193,  0.8391,  0.1854,  0.5397,\n",
      "        -1.4823,  0.4547, -0.4700,  0.6417,  0.2556,  1.3459, -0.6840,  0.0973,\n",
      "         0.5017, -1.1059, -2.6303, -0.7581,  0.3041, -1.4020, -0.1539, -0.3434],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1340.9890, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,   10,  819,   71, 1553,  643,   19,   61,  161,  212,  503,\n",
      "           5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  23, 122, 645,  23,  19,  19,  10,  15,   5,   5,   5,   2,  19,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.4630,  0.8292,  1.7170,  ...,  2.2008,  2.2773,  2.4327],\n",
      "        [-6.8025, -7.0894, -6.4332,  ..., -8.8211, -9.7790, -9.7776],\n",
      "        [ 1.8460,  0.8569, -0.7968,  ...,  3.9372,  3.7617,  2.9209],\n",
      "        ...,\n",
      "        [-3.2765, -3.5775, -2.7453,  ..., -3.7497, -4.3188, -4.3503],\n",
      "        [-3.9518, -4.8383, -2.5528,  ..., -3.8936, -4.2061, -4.1979],\n",
      "        [-4.0229, -3.7319, -2.9581,  ..., -3.7539, -3.9722, -3.8052]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '的', '朋', '友', '邀', '請', '我', '去', '吃', '晚', '餐', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '欢', '候', '不', '我', '我', '的', '一', '。', '。', '。', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.7490e-01, -9.1536e-01,  1.0070e+00, -7.6569e-01,  1.7525e-03,\n",
      "        -3.7871e-02, -3.9685e-02, -4.4137e-01,  1.0591e+00,  6.1909e-01,\n",
      "        -5.5480e-02, -1.7374e+00, -1.6455e+00,  8.6009e-03, -8.9650e-01,\n",
      "         7.3256e-01, -1.2729e+00, -1.4727e-01, -8.8947e-01,  1.2924e+00,\n",
      "         1.5646e+00, -6.6783e-01,  2.0979e+00,  1.0469e+00,  6.3172e-01,\n",
      "         2.3948e-01,  1.1778e+00,  5.0787e-01,  9.5131e-01, -9.2311e-02,\n",
      "         4.8194e-02, -2.3643e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7807, -0.6239, -0.5958, -0.2567,  2.0199,  0.3636,  0.6021, -1.1031,\n",
      "         0.3465, -1.6998,  1.7566, -0.5764, -0.6114,  0.8385,  0.1808,  0.5091,\n",
      "        -1.4569,  0.4389, -0.4476,  0.6199,  0.2727,  1.3430, -0.6874,  0.1269,\n",
      "         0.4934, -1.0589, -2.6333, -0.7395,  0.3235, -1.4179, -0.1653, -0.3318],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1362.2117, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6, 555,  58, 413,  43, 140,  33,   2,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6, 353,   6, 413,  10,  32,  58,   2,   6,  33,  33,  33,  33,  33,\n",
      "         33,  33,  10,  33,  33,  33,  33,  33,  33,  10,   5,  10,   5,  33,\n",
      "         33], device='cuda:0') tensor([[ 0.6238,  0.9880,  1.0157,  ...,  2.1142,  1.7877,  1.3372],\n",
      "        [-5.6863, -7.9642, -9.0275,  ..., -9.7951, -9.3052, -7.1278],\n",
      "        [ 1.7823,  0.9408, -0.4236,  ...,  3.7953,  6.7061,  6.9585],\n",
      "        ...,\n",
      "        [-3.2683, -3.7621, -3.5083,  ..., -3.8956, -3.6376, -3.1668],\n",
      "        [-3.5754, -4.9349, -4.8432,  ..., -4.1021, -3.6578, -3.4270],\n",
      "        [-3.9879, -4.2276, -5.0666,  ..., -4.2615, -4.1510, -3.0423]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '為', '什', '麼', '沒', '做', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '想', '你', '麼', '的', '有', '什', '<eos>', '你', '？', '？', '？', '？', '？', '？', '？', '的', '？', '？', '？', '？', '？', '？', '的', '。', '的', '。', '？', '？']\n",
      "x embedding 0 tensor([-8.8444e-01, -9.1080e-01,  1.0201e+00, -7.4908e-01,  3.5931e-03,\n",
      "        -5.2677e-02, -4.2931e-02, -4.4055e-01,  1.0512e+00,  6.1000e-01,\n",
      "        -5.3804e-02, -1.7223e+00, -1.6401e+00, -1.9262e-03, -8.9699e-01,\n",
      "         7.2628e-01, -1.2603e+00, -1.4076e-01, -8.7482e-01,  1.3029e+00,\n",
      "         1.5495e+00, -6.7663e-01,  2.0880e+00,  1.0474e+00,  6.2573e-01,\n",
      "         2.5017e-01,  1.1913e+00,  5.0250e-01,  9.5900e-01, -9.8783e-02,\n",
      "         4.6818e-02, -2.3568e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7788, -0.6176, -0.5831, -0.2487,  2.0367,  0.3505,  0.5918, -1.0872,\n",
      "         0.3629, -1.6870,  1.7612, -0.5903, -0.6021,  0.8541,  0.1906,  0.5072,\n",
      "        -1.4532,  0.4437, -0.4393,  0.6292,  0.2612,  1.3312, -0.6811,  0.1232,\n",
      "         0.5103, -1.0554, -2.6130, -0.7480,  0.3161, -1.4183, -0.1825, -0.3454],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1342.6290, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6,  51,  84, 545,  19,  68, 349,  35,  33,   2,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6, 51, 23, 19, 19, 10, 22, 10, 33,  2, 19,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.6153,  0.9848,  1.3656,  ...,  1.8940,  1.9822,  1.9116],\n",
      "        [-5.8263, -7.9005, -8.8360,  ..., -8.6180, -8.9203, -9.1339],\n",
      "        [ 2.6027,  1.1137,  0.6123,  ...,  4.4944,  3.5492,  3.4722],\n",
      "        ...,\n",
      "        [-3.3400, -3.6780, -3.8090,  ..., -3.8655, -3.6621, -3.8835],\n",
      "        [-3.8913, -5.0784, -4.9254,  ..., -3.9341, -3.5646, -4.1646],\n",
      "        [-3.9512, -3.9770, -4.3368,  ..., -3.1730, -3.4473, -3.5152]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '能', '再', '给', '我', '点', '茶', '吗', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '能', '不', '我', '我', '的', '了', '的', '？', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8852, -0.9187,  1.0158, -0.7457,  0.0133, -0.0601, -0.0475, -0.4435,\n",
      "         1.0464,  0.6165, -0.0559, -1.7244, -1.6307,  0.0028, -0.9036,  0.7311,\n",
      "        -1.2586, -0.1380, -0.8853,  1.3168,  1.5640, -0.6589,  2.0974,  1.0485,\n",
      "         0.6311,  0.2442,  1.1775,  0.5098,  0.9770, -0.0876,  0.0395, -2.3630],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7659, -0.6029, -0.5802, -0.2385,  2.0443,  0.3533,  0.5916, -1.0836,\n",
      "         0.3699, -1.6874,  1.7589, -0.5942, -0.5932,  0.8593,  0.1867,  0.4900,\n",
      "        -1.4461,  0.4385, -0.4306,  0.6429,  0.2544,  1.3143, -0.6593,  0.1354,\n",
      "         0.5286, -1.0573, -2.6086, -0.7449,  0.3073, -1.4241, -0.1956, -0.3503],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1359.7708, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,  271,  360, 1722, 1572,  239,  140,   58,  413,   33,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  51, 413, 171,  60, 163,  58,  58,  59,  33,   2,   2,   2, 252,\n",
      "         33,  33,  33,  33, 252,  10,  33,  10,   5,  10,  10,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.7222,  1.0817,  1.2037,  ...,  2.2172,  1.6640,  2.0073],\n",
      "        [-5.7342, -7.8017, -5.4923,  ..., -8.9934, -8.0345, -9.6054],\n",
      "        [ 1.8590,  0.8269, -2.9955,  ...,  2.3197,  3.7663,  3.0494],\n",
      "        ...,\n",
      "        [-3.3670, -3.8366, -3.2721,  ..., -3.5563, -3.4498, -4.0982],\n",
      "        [-3.7196, -4.8292, -2.2318,  ..., -3.2889, -3.5720, -3.9944],\n",
      "        [-4.0794, -4.1061, -2.9723,  ..., -3.5067, -3.1291, -3.7366]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '這', '個', '週', '末', '要', '做', '什', '麼', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '能', '麼', '人', '是', '在', '什', '什', '么', '？', '<eos>', '<eos>', '<eos>', '嗎', '？', '？', '？', '？', '嗎', '的', '？', '的', '。', '的', '的', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.9266e-01, -9.0287e-01,  1.0096e+00, -7.4887e-01,  1.5018e-02,\n",
      "        -4.9482e-02, -6.9592e-02, -4.3441e-01,  1.0542e+00,  6.1071e-01,\n",
      "        -4.0989e-02, -1.7175e+00, -1.6377e+00, -7.8236e-04, -9.0994e-01,\n",
      "         7.2553e-01, -1.2619e+00, -1.3373e-01, -8.8096e-01,  1.3264e+00,\n",
      "         1.5746e+00, -6.6768e-01,  2.0923e+00,  1.0323e+00,  6.2599e-01,\n",
      "         2.5468e-01,  1.1585e+00,  5.0316e-01,  9.7565e-01, -9.7626e-02,\n",
      "         3.4958e-02, -2.3565e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7434, -0.6040, -0.5850, -0.2288,  2.0498,  0.3597,  0.6039, -1.0957,\n",
      "         0.3657, -1.6990,  1.7543, -0.5854, -0.5766,  0.8699,  0.1757,  0.4619,\n",
      "        -1.4265,  0.4294, -0.4154,  0.6438,  0.2409,  1.2953, -0.6515,  0.1558,\n",
      "         0.5330, -1.0491, -2.6137, -0.7290,  0.3098, -1.4209, -0.2088, -0.3478],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1363.1859, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  646, 2481,  948,   19,  353,   10,  248,  825,    5,    2,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193, 171, 128,  19,  10,  10,   5,   5,   5,   2,   2,   5,   5,   5,\n",
      "          2,   2,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  2.6419,   3.3578,   3.1211,  ...,   2.3416,   2.4726,   2.2982],\n",
      "        [ -6.0097,  -6.9839,  -9.1476,  ...,  -9.4814, -10.6576,  -9.6261],\n",
      "        [ -1.5893,  -1.6332,  -0.8665,  ...,   4.0815,   3.8395,   3.5099],\n",
      "        ...,\n",
      "        [ -2.8679,  -2.8422,  -3.6357,  ...,  -4.1726,  -4.3284,  -4.2559],\n",
      "        [ -2.6914,  -1.8343,  -3.3572,  ...,  -4.1594,  -4.4631,  -4.3229],\n",
      "        [ -2.8885,  -2.8010,  -3.9324,  ...,  -3.6883,  -4.5198,  -3.7011]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '情', '況', '比', '我', '想', '的', '還', '壞', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '人', '，', '我', '的', '的', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.9633e-01, -8.9661e-01,  1.0197e+00, -7.4965e-01,  2.7080e-02,\n",
      "        -3.0901e-02, -8.9365e-02, -4.3179e-01,  1.0643e+00,  6.1880e-01,\n",
      "        -4.3898e-02, -1.7128e+00, -1.6352e+00,  3.8235e-05, -9.0546e-01,\n",
      "         7.2749e-01, -1.2722e+00, -1.4349e-01, -8.7693e-01,  1.3345e+00,\n",
      "         1.5817e+00, -6.6970e-01,  2.0811e+00,  1.0275e+00,  6.3540e-01,\n",
      "         2.5225e-01,  1.1515e+00,  4.9691e-01,  9.8334e-01, -9.2621e-02,\n",
      "         3.1726e-02, -2.3513e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7574, -0.6309, -0.5932, -0.2394,  2.0480,  0.3526,  0.6062, -1.1024,\n",
      "         0.3468, -1.7062,  1.7467, -0.5858, -0.5755,  0.8693,  0.1813,  0.4392,\n",
      "        -1.4428,  0.4514, -0.4244,  0.6327,  0.2396,  1.3067, -0.6642,  0.1525,\n",
      "         0.5153, -1.0407, -2.5933, -0.7182,  0.3285, -1.4048, -0.1979, -0.3383],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1238.3247, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  228,  580,   19,  206,    6,  836,  101, 1431,  225,  128,   19,\n",
      "         543,  163,   92,  246,    5,    2,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6, 580,  36,  23,   6,  10, 190,   5,   5,   6,   6,  10,  10,  15,\n",
      "          5,   5,   2,   2,   2,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.9964,  1.8650,  1.5434,  ...,  2.3625,  2.3129,  2.0821],\n",
      "        [-7.4803, -7.7878, -9.3853,  ..., -9.5070, -9.3228, -8.7701],\n",
      "        [ 1.6433, -1.2032,  3.6580,  ...,  3.5360,  4.3633,  5.1024],\n",
      "        ...,\n",
      "        [-3.6928, -3.8506, -4.2843,  ..., -3.9805, -3.6998, -3.3083],\n",
      "        [-4.3327, -4.1384, -4.6422,  ..., -3.8905, -3.7478, -3.0190],\n",
      "        [-4.8746, -4.3103, -5.6706,  ..., -3.9065, -3.8482, -3.4898]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '如', '果', '我', '对', '你', '产', '生', '误', '解', '，', '我', '实', '在', '抱', '歉', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '果', '他', '不', '你', '的', '信', '。', '。', '你', '你', '的', '的', '一', '。', '。', '<eos>', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8910, -0.8941,  1.0414, -0.7400,  0.0069, -0.0268, -0.0843, -0.4240,\n",
      "         1.0665,  0.6053, -0.0462, -1.7052, -1.6282, -0.0067, -0.9090,  0.7377,\n",
      "        -1.2736, -0.1552, -0.8725,  1.3324,  1.5752, -0.6743,  2.0631,  1.0209,\n",
      "         0.6541,  0.2497,  1.1575,  0.4825,  0.9667, -0.0871,  0.0310, -2.3413],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7589, -0.6300, -0.5932, -0.2275,  2.0438,  0.3491,  0.6034, -1.1002,\n",
      "         0.3475, -1.6920,  1.7457, -0.5980, -0.5795,  0.8708,  0.1770,  0.4378,\n",
      "        -1.4503,  0.4616, -0.4366,  0.6498,  0.2329,  1.2983, -0.6586,  0.1536,\n",
      "         0.5220, -1.0561, -2.5888, -0.7120,  0.3215, -1.4064, -0.1928, -0.3369],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1564.5452, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,    8,  214,  993,  189, 1438,  140,   22,   58,  413,   33,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  51,  58, 413, 171, 252, 252,  35, 252,  59,  33,   2, 252,  33,\n",
      "         33,  33,  10,  33,  33,  33,  33,  33,  33,  33,  33,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.5243,  1.0592,  1.3382,  ...,  1.9795,  1.9409,  1.9528],\n",
      "        [-5.6914, -7.5414, -8.5739,  ..., -9.0029, -7.8506, -7.8589],\n",
      "        [ 2.5334,  1.0292, -1.9452,  ...,  2.9161,  2.0132,  2.2827],\n",
      "        ...,\n",
      "        [-3.4337, -3.5124, -2.7196,  ..., -3.4936, -3.2985, -3.4503],\n",
      "        [-3.8725, -4.9032, -3.9801,  ..., -3.4829, -3.1392, -3.1119],\n",
      "        [-4.3487, -4.1163, -4.5887,  ..., -3.7849, -3.2770, -3.3530]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '用', '那', '台', '相', '機', '做', '了', '什', '麼', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '能', '什', '麼', '人', '嗎', '嗎', '吗', '嗎', '么', '？', '<eos>', '嗎', '？', '？', '？', '的', '？', '？', '？', '？', '？', '？', '？', '？', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-8.8854e-01, -8.9494e-01,  1.0432e+00, -7.4316e-01,  1.5921e-02,\n",
      "        -1.5179e-02, -9.5095e-02, -4.1893e-01,  1.0736e+00,  6.0198e-01,\n",
      "        -4.7398e-02, -1.7066e+00, -1.6254e+00, -2.0281e-03, -9.0075e-01,\n",
      "         7.4451e-01, -1.2486e+00, -1.4826e-01, -8.7104e-01,  1.3222e+00,\n",
      "         1.5763e+00, -6.9208e-01,  2.0501e+00,  1.0214e+00,  6.5847e-01,\n",
      "         2.4759e-01,  1.1546e+00,  4.6473e-01,  9.6406e-01, -8.3207e-02,\n",
      "         2.6681e-02, -2.3384e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7617, -0.6436, -0.6033, -0.2233,  2.0363,  0.3504,  0.5946, -1.1110,\n",
      "         0.3345, -1.7006,  1.7316, -0.5913, -0.5913,  0.8635,  0.1678,  0.4271,\n",
      "        -1.4530,  0.4702, -0.4418,  0.6456,  0.2412,  1.2995, -0.6590,  0.1641,\n",
      "         0.5205, -1.0547, -2.5856, -0.7020,  0.3267, -1.3964, -0.1886, -0.3260],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1671.1002, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 111, 559, 189, 190,   6,  60, 120, 604,  10,   5,   2,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 23, 98, 32, 22,  5,  5,  5,  5,  5,  5,  2,  5,  5,  2,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[  0.7056,   1.1926,   1.5646,  ...,   1.8094,   2.1586,   2.1105],\n",
      "        [ -7.2170,  -8.2090,  -8.7637,  ...,  -8.4208, -10.5905, -10.2677],\n",
      "        [  1.0271,  -0.1709,   0.4754,  ...,   4.9342,   3.9396,   3.7370],\n",
      "        ...,\n",
      "        [ -3.1180,  -3.6422,  -3.5096,  ...,  -3.4238,  -3.9674,  -4.2683],\n",
      "        [ -3.9442,  -5.0286,  -4.0597,  ...,  -3.8888,  -4.3434,  -4.5793],\n",
      "        [ -4.2127,  -4.2313,  -4.3946,  ...,  -3.0316,  -4.0497,  -3.7723]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '完', '全', '相', '信', '你', '是', '清', '白', '的', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '得', '有', '了', '。', '。', '。', '。', '。', '。', '<eos>', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8940, -0.8865,  1.0330, -0.7492,  0.0209, -0.0125, -0.1100, -0.3967,\n",
      "         1.0762,  0.5974, -0.0470, -1.7023, -1.6354, -0.0075, -0.8907,  0.7365,\n",
      "        -1.2448, -0.1363, -0.8627,  1.3290,  1.5887, -0.7068,  2.0299,  1.0064,\n",
      "         0.6618,  0.2527,  1.1582,  0.4708,  0.9491, -0.0888,  0.0339, -2.3363],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7447, -0.6345, -0.6084, -0.2075,  2.0276,  0.3655,  0.5844, -1.1151,\n",
      "         0.3315, -1.7077,  1.7183, -0.5805, -0.6000,  0.8516,  0.1557,  0.4258,\n",
      "        -1.4460,  0.4554, -0.4362,  0.6509,  0.2450,  1.2940, -0.6419,  0.1710,\n",
      "         0.5346, -1.0565, -2.5975, -0.7060,  0.3198, -1.4022, -0.1875, -0.3245],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1300.9901, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6,  60, 167, 974, 171,   5,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  60,  15, 167, 168,   5,   2,   2,  10,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.6495,  2.0271,  1.7688,  ...,  1.7313,  1.7253,  1.8829],\n",
      "        [-7.4265, -8.6935, -7.0404,  ..., -8.8423, -7.2635, -8.1159],\n",
      "        [ 1.5225,  0.3296, -2.6663,  ...,  3.4798,  2.2341,  2.1002],\n",
      "        ...,\n",
      "        [-3.9842, -4.3329, -3.0935,  ..., -3.6443, -3.0734, -3.4707],\n",
      "        [-3.8769, -4.7766, -3.8539,  ..., -4.3323, -2.7217, -3.4142],\n",
      "        [-4.7636, -4.3955, -3.7349,  ..., -3.2024, -2.4632, -3.0968]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '是', '个', '女', '人', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '是', '一', '个', '子', '。', '<eos>', '<eos>', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8997, -0.8795,  1.0301, -0.7289,  0.0263, -0.0117, -0.1124, -0.3984,\n",
      "         1.0811,  0.5952, -0.0461, -1.6950, -1.6403, -0.0088, -0.8810,  0.7371,\n",
      "        -1.2277, -0.1178, -0.8475,  1.3240,  1.5809, -0.7185,  2.0121,  0.9937,\n",
      "         0.6588,  0.2587,  1.1844,  0.4595,  0.9471, -0.0950,  0.0356, -2.3299],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7532, -0.6381, -0.5996, -0.2056,  2.0398,  0.3484,  0.5803, -1.1004,\n",
      "         0.3476, -1.6906,  1.7290, -0.5959, -0.5903,  0.8669,  0.1656,  0.4267,\n",
      "        -1.4471,  0.4683, -0.4351,  0.6573,  0.2363,  1.2876, -0.6458,  0.1668,\n",
      "         0.5404, -1.0569, -2.5780, -0.7150,  0.3141, -1.3943, -0.1988, -0.3338],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1248.9012, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   63,   64,   86,  118,   19,  128,   78,   19,  101,  909,  214,\n",
      "         266,   19,  722,   51,   91,   17,  190, 1214,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 63,  64,  23, 118,  19,  23,  19,  19,  10,  22,  10,  60,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   2,  19,   2,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  1.1018,   1.5512,   1.9107,  ...,   2.8323,   2.9490,   2.9140],\n",
      "        [ -6.2248,  -7.5938,  -9.0717,  ..., -10.0508, -10.5841, -10.3152],\n",
      "        [  1.6481,   1.6052,   1.7875,  ...,   4.8467,   3.9325,   4.2323],\n",
      "        ...,\n",
      "        [ -2.6174,  -2.7927,  -3.4275,  ...,  -3.5775,  -3.7211,  -3.5330],\n",
      "        [ -3.7809,  -4.4876,  -4.9236,  ...,  -3.8203,  -3.9152,  -3.6939],\n",
      "        [ -4.3128,  -3.8907,  -4.4747,  ...,  -4.0359,  -4.0506,  -3.9894]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '汤', '姆', '告', '诉', '我', '，', '到', '我', '生', '日', '那', '天', '我', '才', '能', '打', '开', '信', '封', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '不', '诉', '我', '不', '我', '我', '的', '了', '的', '是', '。', '。', '。', '。', '。', '。', '。', '。', '<eos>', '我', '<eos>', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.8994, -0.8833,  1.0229, -0.7245,  0.0310,  0.0037, -0.1249, -0.3898,\n",
      "         1.0842,  0.5997, -0.0502, -1.6956, -1.6412, -0.0133, -0.8814,  0.7335,\n",
      "        -1.2361, -0.1218, -0.8509,  1.3274,  1.5881, -0.7181,  2.0078,  0.9815,\n",
      "         0.6588,  0.2561,  1.1685,  0.4671,  0.9517, -0.0909,  0.0407, -2.3385],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7524, -0.6367, -0.6018, -0.1916,  2.0362,  0.3585,  0.5663, -1.0948,\n",
      "         0.3531, -1.6950,  1.7158, -0.5924, -0.6021,  0.8587,  0.1628,  0.4416,\n",
      "        -1.4462,  0.4657, -0.4354,  0.6564,  0.2514,  1.2816, -0.6352,  0.1662,\n",
      "         0.5528, -1.0586, -2.5763, -0.7293,  0.3108, -1.4121, -0.1943, -0.3418],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1476.1730, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  236,   64,   10,  159,  199,  444, 1318,  266,  586,  701,   22,\n",
      "           5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 63,  64, 163, 171, 293, 128, 128, 266,  22,   5,   5,   5,   2,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.7495,  1.8650,  2.3796,  ...,  2.3208,  2.3013,  2.2642],\n",
      "        [-5.9935, -6.0596, -8.2816,  ..., -8.5921, -9.6260, -7.6478],\n",
      "        [ 1.1170,  1.4887,  0.8807,  ...,  2.9976,  3.2426,  2.8973],\n",
      "        ...,\n",
      "        [-2.6002, -2.3413, -3.0352,  ..., -3.2227, -3.5149, -2.8337],\n",
      "        [-3.4465, -4.0569, -4.4562,  ..., -4.0533, -4.3713, -2.9518],\n",
      "        [-3.9527, -3.1135, -3.9944,  ..., -2.9191, -3.5178, -2.5276]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '湯', '姆', '的', '自', '行', '車', '昨', '天', '被', '偷', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '在', '人', '己', '，', '，', '天', '了', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9117, -0.8762,  1.0249, -0.7030,  0.0286,  0.0064, -0.1258, -0.3956,\n",
      "         1.0768,  0.5929, -0.0502, -1.6809, -1.6425, -0.0213, -0.8823,  0.7384,\n",
      "        -1.2285, -0.1209, -0.8444,  1.3407,  1.5738, -0.7168,  1.9973,  0.9691,\n",
      "         0.6571,  0.2650,  1.1788,  0.4646,  0.9663, -0.0900,  0.0373, -2.3315],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7460, -0.6248, -0.5918, -0.1820,  2.0516,  0.3578,  0.5617, -1.0833,\n",
      "         0.3691, -1.6921,  1.7158, -0.5992, -0.5973,  0.8665,  0.1641,  0.4437,\n",
      "        -1.4326,  0.4610, -0.4234,  0.6585,  0.2507,  1.2603, -0.6222,  0.1693,\n",
      "         0.5745, -1.0558, -2.5676, -0.7417,  0.2990, -1.4314, -0.2126, -0.3569],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1291.0618, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   63,   64,  518,  110,   22, 1127, 1128,   10, 1035, 2109,    5,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  63,   64,  163,   22, 1127,  177, 1128,   10,  171,  187,    5,    2,\n",
      "          36,   64,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "           5,    5,    5,    5,    5], device='cuda:0') tensor([[ 1.8271,  2.1894,  2.2166,  ...,  2.3528,  2.4839,  2.0661],\n",
      "        [-5.5693, -7.0293, -7.4257,  ..., -7.2477, -9.1626, -8.1071],\n",
      "        [ 0.1134, -0.1170, -2.0568,  ...,  3.2833,  3.6886,  3.3666],\n",
      "        ...,\n",
      "        [-2.5664, -2.6160, -2.8087,  ..., -2.4286, -3.1248, -2.9899],\n",
      "        [-3.1278, -3.8635, -4.1433,  ..., -2.8204, -3.6942, -4.0655],\n",
      "        [-4.0084, -3.6175, -3.6328,  ..., -2.5920, -3.3788, -2.8480]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '汤', '姆', '亲', '吻', '了', '玛', '丽', '的', '两', '颊', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '在', '了', '玛', '她', '丽', '的', '人', 'o', '。', '<eos>', '他', '姆', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.0235e-01, -8.8018e-01,  1.0250e+00, -7.1468e-01,  2.5791e-02,\n",
      "         5.1392e-04, -1.1203e-01, -3.9761e-01,  1.0699e+00,  5.8407e-01,\n",
      "        -5.3728e-02, -1.6854e+00, -1.6425e+00, -1.1625e-02, -8.8327e-01,\n",
      "         7.3588e-01, -1.2156e+00, -1.0653e-01, -8.3554e-01,  1.3369e+00,\n",
      "         1.5683e+00, -7.3350e-01,  1.9871e+00,  9.7106e-01,  6.5445e-01,\n",
      "         2.6542e-01,  1.1882e+00,  4.6858e-01,  9.4998e-01, -8.8615e-02,\n",
      "         3.2818e-02, -2.3278e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7516, -0.6441, -0.6024, -0.1844,  2.0502,  0.3550,  0.5663, -1.0885,\n",
      "         0.3599, -1.7044,  1.7090, -0.5906, -0.5920,  0.8683,  0.1713,  0.4279,\n",
      "        -1.4323,  0.4632, -0.4141,  0.6394,  0.2569,  1.2700, -0.6338,  0.1754,\n",
      "         0.5661, -1.0319, -2.5541, -0.7390,  0.3092, -1.4265, -0.2165, -0.3532],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1151.4216, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   63,   64, 1125,  104, 1126,  543,    5,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([63, 64, 60, 22, 22,  5,  5,  2, 19,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 0.9533,  1.7976,  1.7594,  ...,  1.8839,  2.1196,  2.0867],\n",
      "        [-5.9871, -7.2067, -8.2609,  ..., -7.8693, -8.6320, -9.3191],\n",
      "        [ 0.9031, -0.0414, -0.1855,  ...,  3.1949,  3.4396,  4.1021],\n",
      "        ...,\n",
      "        [-3.1799, -3.2316, -3.9334,  ..., -3.6452, -4.1122, -4.3034],\n",
      "        [-3.8154, -4.2201, -4.8903,  ..., -3.7105, -4.0799, -4.5392],\n",
      "        [-4.2049, -3.6379, -3.9603,  ..., -3.1467, -3.4756, -3.7599]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '汤', '姆', '言', '过', '其', '实', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '是', '了', '了', '。', '。', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.1843e-01, -8.6539e-01,  1.0196e+00, -6.9182e-01,  2.6583e-02,\n",
      "        -2.9067e-04, -1.1491e-01, -3.9880e-01,  1.0760e+00,  5.7652e-01,\n",
      "        -4.7571e-02, -1.6710e+00, -1.6492e+00, -2.9017e-02, -8.8365e-01,\n",
      "         7.3828e-01, -1.2162e+00, -8.9197e-02, -8.2238e-01,  1.3358e+00,\n",
      "         1.5691e+00, -7.4170e-01,  1.9590e+00,  9.5796e-01,  6.5321e-01,\n",
      "         2.8203e-01,  1.2141e+00,  4.4764e-01,  9.5316e-01, -9.0966e-02,\n",
      "         2.2611e-02, -2.3126e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7553, -0.6402, -0.6032, -0.1597,  2.0528,  0.3518,  0.5404, -1.0758,\n",
      "         0.3751, -1.6884,  1.7043, -0.6068, -0.5946,  0.8704,  0.1731,  0.4337,\n",
      "        -1.4471,  0.4736, -0.4274,  0.6552,  0.2501,  1.2702, -0.6247,  0.1682,\n",
      "         0.5910, -1.0372, -2.5382, -0.7597,  0.2908, -1.4090, -0.2136, -0.3617],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1330.4055, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 239, 364,  58,  59,  33,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  56,  58,  58, 413,  33,   2, 252,  33,  33, 252,  33,  33,  33,\n",
      "         33,  33,  33,   5,   5,  33,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.7507,  1.2969,  1.6463,  ...,  1.4996,  1.8778,  1.8417],\n",
      "        [-5.7480, -8.0279, -9.5717,  ..., -7.6869, -9.4923, -9.6126],\n",
      "        [ 1.4302,  1.0446, -0.6552,  ...,  5.1924,  4.5658,  4.3205],\n",
      "        ...,\n",
      "        [-3.3289, -3.7483, -3.3426,  ..., -3.5635, -3.4923, -3.7533],\n",
      "        [-3.4490, -4.8168, -4.4612,  ..., -3.5527, -3.8675, -4.1928],\n",
      "        [-3.6225, -4.1440, -4.6564,  ..., -3.1305, -3.9221, -3.7788]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '要', '买', '什', '么', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '们', '什', '什', '麼', '？', '<eos>', '嗎', '？', '？', '嗎', '？', '？', '？', '？', '？', '？', '。', '。', '？', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9099, -0.8734,  1.0191, -0.6865,  0.0263,  0.0092, -0.1122, -0.4130,\n",
      "         1.0795,  0.5844, -0.0706, -1.6731, -1.6303, -0.0096, -0.8814,  0.7516,\n",
      "        -1.2136, -0.1073, -0.8305,  1.3346,  1.5823, -0.7289,  1.9811,  0.9779,\n",
      "         0.6658,  0.2707,  1.1977,  0.4619,  0.9639, -0.0719,  0.0261, -2.3203],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7638, -0.6641, -0.6108, -0.1693,  2.0432,  0.3492,  0.5597, -1.0882,\n",
      "         0.3561, -1.6963,  1.7006, -0.5939, -0.5848,  0.8763,  0.1781,  0.3993,\n",
      "        -1.4416,  0.4815, -0.4231,  0.6449,  0.2484,  1.2780, -0.6457,  0.1784,\n",
      "         0.5666, -1.0119, -2.5282, -0.7328,  0.3178, -1.4070, -0.2123, -0.3484],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1457.5432, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,  163, 1053,  767,    5,    2,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 10, 15, 22,  5,  2,  2,  5,  5, 10,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  2,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[ 2.3510,  2.4330,  2.7809,  ...,  2.0749,  2.0622,  1.8688],\n",
      "        [-6.6796, -8.1666, -7.4102,  ..., -9.5516, -8.8910, -9.1927],\n",
      "        [ 0.0161, -0.2988, -3.9805,  ...,  2.4280,  2.2733,  3.5674],\n",
      "        ...,\n",
      "        [-2.9460, -3.6596, -2.2940,  ..., -4.0672, -3.8551, -3.9064],\n",
      "        [-2.7064, -4.1317, -3.0758,  ..., -3.9627, -3.8431, -4.1299],\n",
      "        [-3.0629, -3.2268, -2.6585,  ..., -3.1057, -2.8259, -3.2324]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '在', '關', '門', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '的', '一', '了', '。', '<eos>', '<eos>', '。', '。', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.2242e-01, -8.6320e-01,  1.0061e+00, -6.7275e-01,  2.1975e-02,\n",
      "         1.3319e-03, -1.1869e-01, -4.1395e-01,  1.0765e+00,  5.7844e-01,\n",
      "        -6.0000e-02, -1.6621e+00, -1.6298e+00, -2.0847e-02, -8.8889e-01,\n",
      "         7.5458e-01, -1.2098e+00, -1.1644e-01, -8.2831e-01,  1.3332e+00,\n",
      "         1.5806e+00, -7.2024e-01,  1.9911e+00,  9.8111e-01,  6.6514e-01,\n",
      "         2.7822e-01,  1.2008e+00,  4.5794e-01,  9.7208e-01, -7.3546e-02,\n",
      "         2.2867e-02, -2.3101e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7531, -0.6627, -0.6114, -0.1581,  2.0510,  0.3530,  0.5474, -1.0884,\n",
      "         0.3591, -1.7001,  1.6923, -0.5887, -0.5824,  0.8756,  0.1729,  0.3907,\n",
      "        -1.4346,  0.4829, -0.4172,  0.6444,  0.2532,  1.2579, -0.6333,  0.1895,\n",
      "         0.5801, -1.0128, -2.5255, -0.7378,  0.3138, -1.4082, -0.2204, -0.3498],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1337.3005, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19, 1030,   98,  766,  767,   22,    5,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19, 174,  10,  22,  22,  22,   5,   2,   2,  10,   5,   5,   2,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.4973,  1.9399,  2.2845,  ...,  1.4520,  1.8039,  1.4709],\n",
      "        [-6.4105, -7.5819, -7.1069,  ..., -7.2652, -9.0320, -7.9154],\n",
      "        [ 1.0260, -0.2692, -0.7657,  ...,  4.6789,  3.9924,  4.3104],\n",
      "        ...,\n",
      "        [-2.6562, -3.1069, -2.6583,  ..., -2.9826, -3.2476, -3.1936],\n",
      "        [-3.5842, -4.7082, -3.3677,  ..., -3.7830, -4.0551, -4.1676],\n",
      "        [-3.2898, -3.2490, -2.3687,  ..., -2.3696, -3.0807, -2.6884]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '記', '得', '鎖', '門', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '們', '的', '了', '了', '了', '。', '<eos>', '<eos>', '的', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9186, -0.8600,  1.0111, -0.6749,  0.0290,  0.0139, -0.1123, -0.4124,\n",
      "         1.0914,  0.5754, -0.0625, -1.6657, -1.6251, -0.0200, -0.8779,  0.7636,\n",
      "        -1.2110, -0.1103, -0.8292,  1.3266,  1.5882, -0.7327,  1.9705,  0.9774,\n",
      "         0.6767,  0.2745,  1.2045,  0.4487,  0.9583, -0.0663,  0.0240, -2.3080],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7685, -0.6855, -0.6126, -0.1588,  2.0543,  0.3426,  0.5429, -1.0806,\n",
      "         0.3593, -1.6974,  1.6912, -0.5877, -0.5790,  0.8837,  0.1872,  0.3908,\n",
      "        -1.4387,  0.4987, -0.4199,  0.6350,  0.2576,  1.2654, -0.6460,  0.1841,\n",
      "         0.5796, -0.9914, -2.5059, -0.7447,  0.3267, -1.4087, -0.2222, -0.3575],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1393.2937, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  567,   47,   10,  827,  173,   32, 1409,  161,    5,    2,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60,  10, 171, 278,  60, 171,  10,  22,   2,   5,   5,  10,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  3.1318,   3.8143,   3.5639,  ...,   2.3528,   2.1023,   2.1081],\n",
      "        [ -6.7237,  -7.4184, -10.0173,  ...,  -9.0564,  -7.9374,  -9.0674],\n",
      "        [ -2.2550,  -2.0272,  -1.2910,  ...,   2.7924,   4.7488,   4.9531],\n",
      "        ...,\n",
      "        [ -3.4054,  -3.9689,  -4.0409,  ...,  -3.7326,  -2.9863,  -3.4854],\n",
      "        [ -2.7402,  -1.7606,  -3.5238,  ...,  -4.2789,  -2.9761,  -4.0649],\n",
      "        [ -3.3868,  -2.7259,  -4.4216,  ...,  -2.8144,  -2.5187,  -3.1446]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '早', '起', '的', '鸟', '儿', '有', '虫', '吃', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '的', '人', '方', '是', '人', '的', '了', '<eos>', '。', '。', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9135, -0.8675,  1.0118, -0.6789,  0.0455,  0.0115, -0.1238, -0.4070,\n",
      "         1.0876,  0.5769, -0.0732, -1.6658, -1.6177, -0.0223, -0.8828,  0.7629,\n",
      "        -1.2157, -0.1213, -0.8354,  1.3385,  1.6026, -0.7380,  1.9676,  0.9805,\n",
      "         0.6902,  0.2672,  1.1853,  0.4559,  0.9480, -0.0556,  0.0250, -2.3101],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7775, -0.6966, -0.6177, -0.1524,  2.0423,  0.3429,  0.5391, -1.0833,\n",
      "         0.3541, -1.6964,  1.6817, -0.5857, -0.5898,  0.8834,  0.1895,  0.3903,\n",
      "        -1.4385,  0.5037, -0.4223,  0.6359,  0.2553,  1.2724, -0.6580,  0.1846,\n",
      "         0.5773, -0.9854, -2.5035, -0.7371,  0.3356, -1.4096, -0.2143, -0.3534],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1264.3943, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6, 247,  22, 252, 314,   2,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6, 60, 22, 35, 33,  2, 35, 33, 33, 35, 35, 33,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[  1.0106,   1.5778,   2.2998,  ...,   1.9015,   1.9342,   1.8320],\n",
      "        [ -6.5350,  -8.4992,  -8.9984,  ...,  -8.6227,  -7.9111, -10.4065],\n",
      "        [  3.1069,   1.7003,   0.6561,  ...,   2.5959,   2.3983,   4.4054],\n",
      "        ...,\n",
      "        [ -3.8481,  -4.0138,  -3.3621,  ...,  -3.4500,  -3.2977,  -3.8283],\n",
      "        [ -4.0077,  -5.0307,  -3.0702,  ...,  -4.0438,  -3.2947,  -4.6079],\n",
      "        [ -4.5999,  -4.5260,  -3.9269,  ...,  -2.6535,  -2.3524,  -3.6208]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '累', '了', '嗎', '?', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '是', '了', '吗', '？', '<eos>', '吗', '？', '？', '吗', '吗', '？', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9286, -0.8561,  1.0033, -0.6912,  0.0512,  0.0036, -0.1311, -0.3983,\n",
      "         1.0832,  0.5751, -0.0674, -1.6583, -1.6199, -0.0233, -0.8895,  0.7455,\n",
      "        -1.2168, -0.1127, -0.8277,  1.3468,  1.6127, -0.7386,  1.9692,  0.9709,\n",
      "         0.6805,  0.2746,  1.1822,  0.4700,  0.9451, -0.0670,  0.0230, -2.3030],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7686, -0.6802, -0.6086, -0.1563,  2.0505,  0.3405,  0.5514, -1.0780,\n",
      "         0.3627, -1.6821,  1.6914, -0.5917, -0.5837,  0.8931,  0.1889,  0.3908,\n",
      "        -1.4296,  0.5004, -0.4197,  0.6544,  0.2416,  1.2588, -0.6494,  0.1846,\n",
      "         0.5838, -0.9993, -2.5104, -0.7310,  0.3306, -1.4120, -0.2216, -0.3571],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1424.5557, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  36, 377, 360, 648, 401, 898,  82,  83,  22,   5,   2,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 36, 174, 360, 171, 168, 134,  36,  22,   5,   5,   2,  36,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.4072,  1.9656,  2.0594,  ...,  2.2504,  2.2329,  2.0572],\n",
      "        [-7.2581, -8.8728, -7.2801,  ..., -8.9458, -8.5095, -7.7154],\n",
      "        [ 2.0675, -0.0279, -3.4224,  ...,  2.8340,  2.7830,  3.6850],\n",
      "        ...,\n",
      "        [-3.1496, -3.2398, -2.6378,  ..., -2.9991, -2.8503, -2.6445],\n",
      "        [-4.3618, -5.0890, -3.2853,  ..., -4.1665, -4.2178, -3.7361],\n",
      "        [-5.1951, -4.7295, -3.0783,  ..., -3.1033, -2.9683, -2.5054]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '他', '三', '個', '小', '時', '後', '回', '家', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['他', '們', '個', '人', '子', '上', '他', '了', '。', '。', '<eos>', '他', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9342, -0.8422,  1.0110, -0.6921,  0.0377,  0.0070, -0.1270, -0.3993,\n",
      "         1.0889,  0.5623, -0.0657, -1.6524, -1.6363, -0.0218, -0.8873,  0.7419,\n",
      "        -1.2045, -0.0997, -0.8126,  1.3341,  1.6041, -0.7577,  1.9557,  0.9479,\n",
      "         0.6813,  0.2787,  1.1923,  0.4674,  0.9327, -0.0814,  0.0215, -2.2916],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7715, -0.6946, -0.6088, -0.1529,  2.0563,  0.3373,  0.5601, -1.0778,\n",
      "         0.3621, -1.6936,  1.6879, -0.5903, -0.5679,  0.9069,  0.1941,  0.3721,\n",
      "        -1.4151,  0.4986, -0.4062,  0.6455,  0.2357,  1.2547, -0.6620,  0.1914,\n",
      "         0.5809, -0.9798, -2.4967, -0.7292,  0.3356, -1.4105, -0.2393, -0.3624],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1349.1835, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 271, 164,  32,  15, 601, 602,   5,   2,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60,  60,  15, 167,   7,   5,   2,   2,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  2.4620,   2.5434,   2.7485,  ...,   1.8685,   1.5914,   1.8522],\n",
      "        [ -7.2879,  -8.5160, -10.1137,  ...,  -9.0529,  -9.1172,  -8.9636],\n",
      "        [ -0.5888,  -2.7245,  -1.3029,  ...,   3.0909,   4.0570,   3.4270],\n",
      "        ...,\n",
      "        [ -3.8172,  -4.1460,  -4.4198,  ...,  -3.2777,  -3.5054,  -3.5962],\n",
      "        [ -3.1006,  -3.5823,  -4.4398,  ...,  -3.7838,  -4.4690,  -4.0205],\n",
      "        [ -3.6196,  -3.2796,  -4.1772,  ...,  -2.8906,  -2.8944,  -2.8719]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '這', '裡', '有', '一', '本', '書', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '是', '一', '个', '好', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.2727e-01, -8.4521e-01,  1.0101e+00, -6.9408e-01,  4.3607e-02,\n",
      "         9.5182e-04, -1.2839e-01, -4.0533e-01,  1.1035e+00,  5.6066e-01,\n",
      "        -7.0811e-02, -1.6559e+00, -1.6240e+00, -1.7158e-02, -8.7915e-01,\n",
      "         7.5101e-01, -1.1862e+00, -9.3399e-02, -8.2253e-01,  1.3387e+00,\n",
      "         1.6172e+00, -7.7108e-01,  1.9466e+00,  9.5444e-01,  6.9167e-01,\n",
      "         2.7784e-01,  1.1913e+00,  4.4973e-01,  9.2839e-01, -7.5543e-02,\n",
      "         1.1880e-02, -2.2938e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7767, -0.6890, -0.5864, -0.1549,  2.0683,  0.3214,  0.5650, -1.0570,\n",
      "         0.3762, -1.6748,  1.7060, -0.6103, -0.5561,  0.9271,  0.2076,  0.3732,\n",
      "        -1.4143,  0.5057, -0.4038,  0.6625,  0.2121,  1.2531, -0.6677,  0.1783,\n",
      "         0.5944, -0.9884, -2.4813, -0.7281,  0.3366, -1.4113, -0.2497, -0.3798],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1382.6477, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6, 163, 794, 143,  58,  59, 709,  33,   2,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  60,  58,  33, 252,  59,  33,  33,   2,   2,  10, 252, 252,  33,\n",
      "         33,  35, 252,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.8286,  1.3710,  1.6410,  ...,  1.3962,  1.8017,  1.7945],\n",
      "        [-6.3335, -8.4181, -8.9475,  ..., -8.7032, -8.8243, -9.4900],\n",
      "        [ 2.5942,  0.4840, -1.8944,  ...,  3.4987,  2.9701,  3.8799],\n",
      "        ...,\n",
      "        [-3.4100, -3.5544, -2.2995,  ..., -2.7499, -2.6988, -2.7164],\n",
      "        [-4.1745, -4.6865, -3.7538,  ..., -4.2278, -3.5306, -3.7990],\n",
      "        [-4.4803, -4.1855, -4.5544,  ..., -2.7350, -2.6034, -2.9589]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '在', '担', '心', '什', '么', '呢', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '是', '什', '？', '嗎', '么', '？', '？', '<eos>', '<eos>', '的', '嗎', '嗎', '？', '？', '吗', '嗎', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9382, -0.8419,  1.0062, -0.6957,  0.0572, -0.0118, -0.1406, -0.3873,\n",
      "         1.1054,  0.5593, -0.0651, -1.6517, -1.6239, -0.0221, -0.8819,  0.7421,\n",
      "        -1.1734, -0.0887, -0.8191,  1.3535,  1.6380, -0.7644,  1.9453,  0.9520,\n",
      "         0.7059,  0.2798,  1.1767,  0.4613,  0.9273, -0.0687,  0.0203, -2.2959],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7608, -0.6907, -0.6003, -0.1407,  2.0591,  0.3365,  0.5743, -1.0724,\n",
      "         0.3626, -1.6958,  1.6885, -0.5938, -0.5559,  0.9225,  0.1958,  0.3480,\n",
      "        -1.3963,  0.4901, -0.3879,  0.6579,  0.2059,  1.2526, -0.6614,  0.2046,\n",
      "         0.5979, -0.9678, -2.4889, -0.7070,  0.3406, -1.4229, -0.2640, -0.3699],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1500.5063, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,   60,  271, 1390,  834,  168,   10,  905,  171,  252,   33,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  51,  58, 167, 295, 413,  10,  33,  33,  33,  33,   2, 252, 252,\n",
      "         33,  35,  35,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 0.9532,  1.3752,  1.8683,  ...,  1.8171,  1.7058,  1.9672],\n",
      "        [-6.4822, -8.4806, -9.1953,  ..., -9.0330, -8.4986, -8.2601],\n",
      "        [ 1.2694,  0.3798, -3.1482,  ...,  3.5593,  3.5343,  3.0283],\n",
      "        ...,\n",
      "        [-3.3376, -3.3975, -2.1284,  ..., -2.7334, -2.7184, -2.2521],\n",
      "        [-4.1180, -4.9399, -4.1150,  ..., -3.9091, -3.9429, -3.0263],\n",
      "        [-4.7021, -4.5728, -4.7551,  ..., -2.6916, -2.5618, -2.4515]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '是', '這', '棟', '房', '子', '的', '主', '人', '嗎', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '能', '什', '个', '时', '麼', '的', '？', '？', '？', '？', '<eos>', '嗎', '嗎', '？', '吗', '吗', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9340, -0.8407,  0.9987, -0.6915,  0.0563,  0.0027, -0.1560, -0.3836,\n",
      "         1.1052,  0.5655, -0.0699, -1.6481, -1.6206, -0.0271, -0.8805,  0.7504,\n",
      "        -1.1850, -0.0922, -0.8167,  1.3526,  1.6503, -0.7550,  1.9456,  0.9450,\n",
      "         0.7093,  0.2787,  1.1763,  0.4631,  0.9109, -0.0647,  0.0224, -2.2917],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7598, -0.6975, -0.6038, -0.1057,  2.0584,  0.3367,  0.5435, -1.0613,\n",
      "         0.3707, -1.6982,  1.6722, -0.6021, -0.5597,  0.9157,  0.1927,  0.3442,\n",
      "        -1.3996,  0.4953, -0.3859,  0.6636,  0.2123,  1.2414, -0.6503,  0.2095,\n",
      "         0.6266, -0.9704, -2.4765, -0.7237,  0.3287, -1.4215, -0.2621, -0.3785],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1440.8994, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3, 1196,  597,  512,   10,  649,  597,   32,   68,  801,    5,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([271, 171, 171,  60, 171, 171,   5,   5,   5,   5,   2,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 3.4758,  3.9861,  4.2355,  ...,  2.1453,  1.8246,  2.0553],\n",
      "        [-6.6249, -8.6691, -8.8764,  ..., -7.4935, -6.5857, -8.3351],\n",
      "        [-1.6809, -2.1435, -2.4133,  ...,  4.3852,  4.9524,  3.8915],\n",
      "        ...,\n",
      "        [-2.7070, -3.0023, -3.1357,  ..., -2.5364, -2.5527, -2.5115],\n",
      "        [-2.4294, -2.6001, -2.1328,  ..., -3.5339, -3.5324, -4.0005],\n",
      "        [-2.8268, -2.8274, -2.2869,  ..., -1.8738, -1.6134, -2.0571]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '收', '音', '机', '的', '声', '音', '有', '点', '响', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['這', '人', '人', '是', '人', '人', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9351, -0.8422,  1.0004, -0.6886,  0.0547,  0.0063, -0.1550, -0.3833,\n",
      "         1.0944,  0.5651, -0.0729, -1.6413, -1.6132, -0.0314, -0.8877,  0.7468,\n",
      "        -1.1936, -0.0968, -0.8171,  1.3615,  1.6410, -0.7490,  1.9450,  0.9432,\n",
      "         0.7106,  0.2791,  1.1815,  0.4706,  0.9172, -0.0600,  0.0201, -2.2926],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7742, -0.7146, -0.6074, -0.1045,  2.0472,  0.3331,  0.5405, -1.0619,\n",
      "         0.3616, -1.6969,  1.6659, -0.5998, -0.5707,  0.9097,  0.1978,  0.3403,\n",
      "        -1.4054,  0.5073, -0.3916,  0.6637,  0.2189,  1.2493, -0.6632,  0.2075,\n",
      "         0.6195, -0.9660, -2.4669, -0.7182,  0.3445, -1.4241, -0.2501, -0.3761],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1405.7910, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,   6, 353,  84, 239,  27, 349,  35,  33,   2,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  51, 163,  10, 412, 681, 252,  33,   2, 252,  33,  10,  33,  33,\n",
      "         33,  33,  33,  33,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.1863,  1.6643,  1.8065,  ...,  1.3185,  1.7339,  1.7731],\n",
      "        [-5.9898, -8.7255, -9.4908,  ..., -7.2901, -7.0964, -7.8725],\n",
      "        [ 1.4501,  0.7450, -1.6477,  ...,  7.0655,  3.7136,  3.7930],\n",
      "        ...,\n",
      "        [-3.3255, -3.3536, -2.9004,  ..., -2.4046, -2.4334, -2.4818],\n",
      "        [-3.9944, -4.7819, -3.7906,  ..., -3.7062, -3.0323, -3.3885],\n",
      "        [-4.3742, -4.3280, -4.0764,  ..., -1.9007, -1.5596, -1.8656]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '想', '再', '要', '杯', '茶', '吗', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '能', '在', '的', '哪', '少', '嗎', '？', '<eos>', '嗎', '？', '的', '？', '？', '？', '？', '？', '？', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9339, -0.8375,  1.0044, -0.6795,  0.0558, -0.0094, -0.1496, -0.3998,\n",
      "         1.0979,  0.5537, -0.0825, -1.6345, -1.6125, -0.0367, -0.8886,  0.7603,\n",
      "        -1.1938, -0.1021, -0.8137,  1.3637,  1.6377, -0.7594,  1.9278,  0.9464,\n",
      "         0.7124,  0.2797,  1.1892,  0.4449,  0.9102, -0.0574,  0.0135, -2.2840],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7851, -0.7311, -0.6093, -0.1045,  2.0473,  0.3272,  0.5506, -1.0603,\n",
      "         0.3580, -1.6964,  1.6648, -0.6000, -0.5650,  0.9216,  0.2084,  0.3269,\n",
      "        -1.3991,  0.5166, -0.3855,  0.6648,  0.2136,  1.2543, -0.6766,  0.2087,\n",
      "         0.6163, -0.9481, -2.4499, -0.7113,  0.3585, -1.4254, -0.2572, -0.3821],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1373.5592, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   63,   64,  312,   57, 1127, 1128,   24,  348,  122,  214,   59,\n",
      "         140,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  63,   64,   23,   23,   63, 1128,   23,  140,  122,  177,  164,    5,\n",
      "           5,    2,    2,   64,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "           5,    5,    5,    5,    5], device='cuda:0') tensor([[  0.8554,   1.3030,   1.6023,  ...,   1.9620,   1.9013,   1.6991],\n",
      "        [ -6.7916,  -7.9945,  -9.7034,  ..., -10.3403, -11.2050,  -9.2845],\n",
      "        [  0.8293,   0.7169,   0.5757,  ...,   3.9369,   4.3982,   3.8905],\n",
      "        ...,\n",
      "        [ -3.1706,  -3.2917,  -4.0168,  ...,  -3.1753,  -3.4988,  -3.0075],\n",
      "        [ -4.6061,  -4.9346,  -5.4283,  ...,  -4.2418,  -4.5670,  -3.8544],\n",
      "        [ -4.9731,  -4.4206,  -4.9946,  ...,  -3.1781,  -3.7629,  -2.9183]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '汤', '姆', '以', '为', '玛', '丽', '会', '喜', '欢', '那', '么', '做', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['汤', '姆', '不', '不', '汤', '丽', '不', '做', '欢', '她', '裡', '。', '。', '<eos>', '<eos>', '姆', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9361, -0.8280,  0.9989, -0.6672,  0.0469,  0.0096, -0.1509, -0.4034,\n",
      "         1.1136,  0.5590, -0.0880, -1.6330, -1.6274, -0.0290, -0.8721,  0.7580,\n",
      "        -1.1862, -0.0810, -0.8003,  1.3464,  1.6326, -0.7657,  1.9235,  0.9286,\n",
      "         0.7042,  0.2870,  1.2011,  0.4462,  0.9089, -0.0676,  0.0186, -2.2812],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.8000, -0.7529, -0.6139, -0.1091,  2.0412,  0.3262,  0.5453, -1.0648,\n",
      "         0.3517, -1.7017,  1.6575, -0.5954, -0.5705,  0.9166,  0.2131,  0.3300,\n",
      "        -1.4045,  0.5257, -0.3883,  0.6457,  0.2277,  1.2605, -0.6934,  0.2030,\n",
      "         0.6016, -0.9369, -2.4396, -0.7198,  0.3719, -1.4255, -0.2494, -0.3828],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1373.8716, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  214,  360,  277,  289,   10,  602, 1555,  242,  623, 1836, 1042,\n",
      "        1081,   10,  156,  101,  323,   16,   61,    5,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60, 171,  60, 529, 171, 128, 163, 412,  10, 163,  18,  10,   5,\n",
      "          5,   5,   5,   5,   5,   2,   2,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 3.1561,  3.1577,  4.0669,  ...,  3.1990,  2.2025,  2.8576],\n",
      "        [-6.9759, -7.2549, -8.7111,  ..., -8.8847, -6.9397, -7.4118],\n",
      "        [-3.1782, -4.5281, -2.1220,  ...,  3.2539,  6.0428,  2.8233],\n",
      "        ...,\n",
      "        [-3.0643, -3.9173, -3.5083,  ..., -2.6467, -2.2726, -2.4987],\n",
      "        [-2.9046, -2.6264, -1.8795,  ..., -2.7015, -3.0868, -2.5172],\n",
      "        [-3.6178, -3.0910, -3.3927,  ..., -2.0513, -1.4613, -1.4877]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '那', '個', '地', '點', '的', '書', '店', '無', '法', '賺', '足', '夠', '的', '錢', '生', '存', '下', '去', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '人', '是', '都', '人', '，', '在', '哪', '的', '在', '始', '的', '。', '。', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9385, -0.8265,  0.9967, -0.6668,  0.0382,  0.0238, -0.1544, -0.4083,\n",
      "         1.0996,  0.5618, -0.0954, -1.6271, -1.6272, -0.0343, -0.8769,  0.7588,\n",
      "        -1.1832, -0.0863, -0.8015,  1.3456,  1.6304, -0.7636,  1.9238,  0.9238,\n",
      "         0.7035,  0.2880,  1.2046,  0.4576,  0.9152, -0.0575,  0.0143, -2.2789],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7927, -0.7487, -0.6178, -0.0991,  2.0437,  0.3245,  0.5452, -1.0675,\n",
      "         0.3508, -1.6993,  1.6565, -0.6024, -0.5645,  0.9188,  0.2044,  0.3144,\n",
      "        -1.4048,  0.5273, -0.3904,  0.6569,  0.2127,  1.2503, -0.6828,  0.2115,\n",
      "         0.6082, -0.9399, -2.4376, -0.7123,  0.3635, -1.4151, -0.2572, -0.3784],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1280.5908, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([18, 30]) tensor([   3,   19,   10, 1080, 1080,   60,  749,  999,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([18, 2643, 29]) tensor([ 19,  10,  15,  60,  10,  15, 143,   5,   2,   2,  10,   5,   5,   5,\n",
      "          5,   5,   5,   5,   2,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.0435,  2.5064,  3.2612,  ...,  3.1374,  3.1490,  3.0170],\n",
      "        [-7.6415, -8.6094, -8.2569,  ..., -8.7592, -9.3916, -9.2240],\n",
      "        [ 2.0222,  1.1241, -1.8776,  ...,  3.2906,  3.7547,  4.0887],\n",
      "        ...,\n",
      "        [-2.9453, -3.4880, -2.8085,  ..., -2.7923, -2.7380, -2.8583],\n",
      "        [-3.3322, -4.5686, -2.8738,  ..., -3.3068, -3.4585, -3.4240],\n",
      "        [-3.6240, -3.3994, -3.1940,  ..., -2.1509, -2.2734, -2.0945]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '的', '妹', '妹', '是', '老', '师', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '的', '一', '是', '的', '一', '心', '。', '<eos>', '<eos>', '的', '。', '。', '。', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9419, -0.8220,  1.0071, -0.6612,  0.0254,  0.0291, -0.1656, -0.4042,\n",
      "         1.0967,  0.5555, -0.0902, -1.6188, -1.6166, -0.0368, -0.8796,  0.7668,\n",
      "        -1.1815, -0.0871, -0.7953,  1.3557,  1.6352, -0.7640,  1.9237,  0.9243,\n",
      "         0.7144,  0.2938,  1.2004,  0.4542,  0.9113, -0.0617,  0.0076, -2.2720],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7805, -0.7518, -0.6349, -0.0850,  2.0316,  0.3387,  0.5334, -1.0844,\n",
      "         0.3362, -1.7160,  1.6369, -0.5912, -0.5713,  0.9038,  0.1857,  0.2978,\n",
      "        -1.4027,  0.5243, -0.3931,  0.6519,  0.2262,  1.2411, -0.6678,  0.2297,\n",
      "         0.6079, -0.9417, -2.4449, -0.7070,  0.3584, -1.4065, -0.2515, -0.3605],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(904.3218, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 576, 577,  31, 171, 189, 190, 177,   5,   2,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([643, 266,  23,  32,  10,   5,   5,   5,   2,  36,   5,   5,   5,   5,\n",
      "          5,   5,   5,   2,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 2.2899,  2.6171,  2.3438,  ...,  2.4461,  2.4481,  2.2651],\n",
      "        [-6.7511, -8.4048, -8.8843,  ..., -9.5688, -8.8510, -7.9729],\n",
      "        [-1.8569, -4.3072, -2.1233,  ...,  4.4684,  3.5964,  4.1609],\n",
      "        ...,\n",
      "        [-2.4343, -2.8206, -3.2506,  ..., -3.3061, -3.2776, -3.0281],\n",
      "        [-3.5466, -3.4284, -4.6871,  ..., -4.3355, -4.0953, -3.7447],\n",
      "        [-3.8492, -3.4897, -4.4427,  ..., -3.1196, -2.8331, -2.5795]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '几', '乎', '没', '人', '相', '信', '她', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['請', '天', '不', '有', '的', '。', '。', '。', '<eos>', '他', '。', '。', '。', '。', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9410, -0.8179,  1.0092, -0.6640,  0.0349,  0.0277, -0.1686, -0.3944,\n",
      "         1.0905,  0.5478, -0.0965, -1.6188, -1.6229, -0.0352, -0.8757,  0.7677,\n",
      "        -1.1781, -0.0909, -0.7872,  1.3440,  1.6392, -0.7705,  1.9152,  0.9225,\n",
      "         0.7197,  0.2979,  1.1985,  0.4659,  0.8953, -0.0634,  0.0163, -2.2672],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7799, -0.7533, -0.6344, -0.0754,  2.0296,  0.3402,  0.5310, -1.0818,\n",
      "         0.3399, -1.7149,  1.6356, -0.5945, -0.5629,  0.9062,  0.1840,  0.2974,\n",
      "        -1.3992,  0.5238, -0.3896,  0.6548,  0.2201,  1.2318, -0.6667,  0.2284,\n",
      "         0.6167, -0.9397, -2.4401, -0.7135,  0.3537, -1.4068, -0.2532, -0.3669],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1453.9414, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 214,  23,  60, 623, 470,   5,   2,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60,  60,   6,   5,   5,   2,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  2.0950,   2.2265,   1.9941,  ...,   1.1452,   1.6989,   1.9141],\n",
      "        [ -7.6816,  -8.9032, -10.3096,  ...,  -6.6870,  -8.7451,  -9.4896],\n",
      "        [ -0.0890,  -0.9141,  -0.5144,  ...,   7.0734,   4.1665,   3.3645],\n",
      "        ...,\n",
      "        [ -3.8489,  -4.9115,  -4.6326,  ...,  -2.9367,  -3.2554,  -3.5555],\n",
      "        [ -3.6161,  -4.1983,  -5.4160,  ...,  -3.2724,  -4.3131,  -4.4422],\n",
      "        [ -3.9213,  -3.9101,  -4.7006,  ...,  -1.7904,  -2.1575,  -2.6726]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '那', '不', '是', '法', '语', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '是', '你', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9458, -0.8082,  1.0112, -0.6614,  0.0289,  0.0251, -0.1726, -0.4011,\n",
      "         1.0917,  0.5404, -0.1061, -1.6105, -1.6301, -0.0424, -0.8741,  0.7739,\n",
      "        -1.1701, -0.0760, -0.7765,  1.3313,  1.6342, -0.7755,  1.9056,  0.9111,\n",
      "         0.7172,  0.3047,  1.2176,  0.4537,  0.8864, -0.0717,  0.0081, -2.2560],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7759, -0.7455, -0.6222, -0.0692,  2.0436,  0.3352,  0.5296, -1.0723,\n",
      "         0.3525, -1.7108,  1.6393, -0.6012, -0.5541,  0.9183,  0.1884,  0.3011,\n",
      "        -1.3881,  0.5244, -0.3752,  0.6664,  0.2166,  1.2159, -0.6580,  0.2298,\n",
      "         0.6347, -0.9384, -2.4309, -0.7197,  0.3497, -1.4090, -0.2695, -0.3785],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1441.7349, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,  174, 1544,  229,  189,  351,    5,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  10,  10, 266,  10, 190,   5,   2,   5,   2,   2,   5,  10,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 1.2288,  1.5452,  1.6128,  ...,  1.8385,  1.7148,  1.4362],\n",
      "        [-8.0329, -9.5800, -9.7860,  ..., -8.8370, -9.4928, -7.3198],\n",
      "        [ 1.2821,  0.4739, -0.2064,  ...,  3.8614,  5.0140,  5.4504],\n",
      "        ...,\n",
      "        [-3.0238, -3.6696, -3.5433,  ..., -3.1933, -3.0713, -3.0684],\n",
      "        [-4.0628, -5.5106, -5.5080,  ..., -3.4576, -4.2180, -3.5652],\n",
      "        [-4.4159, -4.5150, -4.4496,  ..., -2.6682, -2.7543, -2.0494]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '們', '彼', '此', '相', '愛', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '的', '的', '天', '的', '信', '。', '<eos>', '。', '<eos>', '<eos>', '。', '的', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9537, -0.8025,  1.0058, -0.6611,  0.0215,  0.0162, -0.1715, -0.3939,\n",
      "         1.0953,  0.5348, -0.1030, -1.6046, -1.6344, -0.0454, -0.8693,  0.7734,\n",
      "        -1.1555, -0.0688, -0.7796,  1.3262,  1.6333, -0.7754,  1.8952,  0.8959,\n",
      "         0.7237,  0.3034,  1.2247,  0.4412,  0.8984, -0.0738,  0.0041, -2.2573],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7792, -0.7519, -0.6232, -0.0761,  2.0473,  0.3307,  0.5365, -1.0734,\n",
      "         0.3462, -1.7142,  1.6377, -0.5982, -0.5484,  0.9221,  0.1946,  0.2869,\n",
      "        -1.3866,  0.5313, -0.3724,  0.6601,  0.2195,  1.2137, -0.6599,  0.2369,\n",
      "         0.6308, -0.9330, -2.4227, -0.7129,  0.3596, -1.4052, -0.2735, -0.3761],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1349.8176, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19,  73,  63,  64, 131, 201,  23, 181,   5,   2,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 23, 63, 64, 10, 22, 22, 60,  5,  2,  2,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[  1.3213,   1.9334,   2.0099,  ...,   2.3784,   2.1465,   1.9907],\n",
      "        [ -6.5354,  -7.4045,  -7.6644,  ..., -10.8459, -10.1401,  -8.1972],\n",
      "        [ -0.7989,  -1.7873,  -0.9413,  ...,   3.9017,   4.1961,   3.9887],\n",
      "        ...,\n",
      "        [ -2.1102,  -2.5061,  -2.2394,  ...,  -3.3288,  -3.1849,  -3.0401],\n",
      "        [ -3.7851,  -5.0625,  -4.8240,  ...,  -4.1880,  -4.1642,  -3.5039],\n",
      "        [ -3.5363,  -3.6372,  -4.3156,  ...,  -3.0634,  -2.9517,  -2.3009]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '和', '汤', '姆', '无', '话', '不', '说', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '汤', '姆', '的', '了', '了', '是', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9546, -0.7999,  0.9998, -0.6653,  0.0388,  0.0161, -0.1820, -0.3872,\n",
      "         1.1064,  0.5375, -0.1043, -1.6061, -1.6246, -0.0427, -0.8636,  0.7728,\n",
      "        -1.1586, -0.0621, -0.7841,  1.3342,  1.6583, -0.7714,  1.8980,  0.9032,\n",
      "         0.7290,  0.3072,  1.2163,  0.4397,  0.8866, -0.0658,  0.0079, -2.2597],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7795, -0.7475, -0.6161, -0.0763,  2.0600,  0.3199,  0.5405, -1.0653,\n",
      "         0.3556, -1.7068,  1.6455, -0.6076, -0.5383,  0.9366,  0.2024,  0.2833,\n",
      "        -1.3853,  0.5359, -0.3733,  0.6663,  0.2042,  1.2078, -0.6575,  0.2324,\n",
      "         0.6393, -0.9340, -2.4135, -0.7125,  0.3532, -1.3984, -0.2863, -0.3857],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1297.0531, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19,  97,  98,   6, 163, 704, 182,   5,   2,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 23, 98, 19, 10,  5,  5,  5,  2,  2,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[  0.5540,   0.9752,   1.5936,  ...,   1.8769,   2.0113,   2.3599],\n",
      "        [ -7.0028,  -8.4286,  -5.8267,  ...,  -7.8860, -10.5512,  -9.4993],\n",
      "        [  0.8593,  -0.2503,   4.9971,  ...,   3.2850,   4.2006,   3.4812],\n",
      "        ...,\n",
      "        [ -2.7812,  -3.5022,  -1.5986,  ...,  -3.0605,  -3.5932,  -2.8762],\n",
      "        [ -4.3518,  -5.7986,  -2.1720,  ...,  -3.1139,  -4.7027,  -3.1439],\n",
      "        [ -3.8423,  -4.2495,  -2.6598,  ...,  -2.2944,  -3.2975,  -2.6453]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '觉', '得', '你', '在', '撒', '谎', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '得', '我', '的', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9524, -0.7965,  0.9948, -0.6581,  0.0454,  0.0142, -0.1861, -0.3803,\n",
      "         1.1056,  0.5425, -0.1009, -1.6066, -1.6234, -0.0379, -0.8609,  0.7744,\n",
      "        -1.1436, -0.0578, -0.7771,  1.3296,  1.6530, -0.7655,  1.9050,  0.9009,\n",
      "         0.7317,  0.3060,  1.2270,  0.4471,  0.8816, -0.0667,  0.0131, -2.2514],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7857, -0.7656, -0.6329, -0.0517,  2.0469,  0.3221,  0.5270, -1.0702,\n",
      "         0.3447, -1.7135,  1.6248, -0.6054, -0.5470,  0.9266,  0.1982,  0.2661,\n",
      "        -1.3923,  0.5432, -0.3755,  0.6651,  0.2109,  1.2059, -0.6591,  0.2489,\n",
      "         0.6447, -0.9222, -2.3997, -0.7085,  0.3571, -1.3924, -0.2808, -0.3758],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1269.3745, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  239,   19,  225, 1956,  545,    6,   48,   60,   23,   50,   51,\n",
      "          10,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 6,  6, 23, 19,  6, 19, 10, 22,  6, 60, 51,  7,  5,  2, 19,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5, 33,  5,  5,  5,  5,  5], device='cuda:0') tensor([[  1.0425,   1.8663,   1.8319,  ...,   1.8312,   2.1186,   2.1663],\n",
      "        [ -8.2008, -12.1872, -10.9388,  ..., -10.3930, -11.3335, -10.1137],\n",
      "        [ -0.6765,   0.4405,  -1.6046,  ...,   4.5534,   4.4127,   3.8745],\n",
      "        ...,\n",
      "        [ -3.7374,  -4.4308,  -3.8258,  ...,  -3.3224,  -3.7391,  -2.9143],\n",
      "        [ -4.7342,  -6.0548,  -5.8736,  ...,  -4.0803,  -4.0409,  -2.9463],\n",
      "        [ -5.1666,  -6.2394,  -5.2916,  ...,  -3.9741,  -4.5722,  -3.8667]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '要', '我', '解', '释', '给', '你', '听', '是', '不', '可', '能', '的', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '你', '不', '我', '你', '我', '的', '了', '你', '是', '能', '好', '。', '<eos>', '我', '。', '。', '。', '。', '。', '。', '。', '。', '？', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.5828e-01, -7.8775e-01,  9.9771e-01, -6.5630e-01,  4.2369e-02,\n",
      "         1.5092e-02, -1.9629e-01, -3.9123e-01,  1.0996e+00,  5.3519e-01,\n",
      "        -1.0379e-01, -1.5903e+00, -1.6130e+00, -4.4982e-02, -8.6882e-01,\n",
      "         7.8405e-01, -1.1382e+00, -6.4532e-02, -7.7325e-01,  1.3410e+00,\n",
      "         1.6448e+00, -7.7518e-01,  1.8937e+00,  9.0228e-01,  7.3715e-01,\n",
      "         3.1436e-01,  1.2339e+00,  4.3820e-01,  8.8697e-01, -6.1151e-02,\n",
      "        -8.9874e-04, -2.2451e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7853, -0.7593, -0.6319, -0.0556,  2.0513,  0.3151,  0.5478, -1.0642,\n",
      "         0.3468, -1.6966,  1.6350, -0.6217, -0.5311,  0.9396,  0.2027,  0.2417,\n",
      "        -1.3997,  0.5499, -0.3859,  0.6861,  0.1855,  1.2017, -0.6534,  0.2556,\n",
      "         0.6485, -0.9281, -2.3930, -0.6882,  0.3524, -1.3756, -0.2883, -0.3757],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1298.6121, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 177,  60, 854, 101,   5,   2,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([177,  10, 167,  10,   5,   2,  36,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  1.6640,   2.4695,   2.7627,  ...,   2.4974,   2.4344,   1.9897],\n",
      "        [ -7.1805,  -9.2056,  -7.8852,  ...,  -9.8778, -10.9546,  -9.6654],\n",
      "        [  1.0401,  -0.6968,  -3.4439,  ...,   3.7654,   4.2921,   5.8046],\n",
      "        ...,\n",
      "        [ -2.3497,  -3.1258,  -2.2558,  ...,  -3.0944,  -3.4528,  -3.0754],\n",
      "        [ -3.2525,  -4.5843,  -4.1098,  ...,  -3.4306,  -3.9267,  -4.0237],\n",
      "        [ -4.2944,  -4.3385,  -3.8604,  ...,  -2.6333,  -3.2021,  -2.5335]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '她', '是', '医', '生', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['她', '的', '个', '的', '。', '<eos>', '他', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9558, -0.7947,  0.9850, -0.6525,  0.0421,  0.0128, -0.1822, -0.3777,\n",
      "         1.0960,  0.5489, -0.0988, -1.5952, -1.6080, -0.0364, -0.8685,  0.7756,\n",
      "        -1.1383, -0.0688, -0.7838,  1.3508,  1.6544, -0.7674,  1.8951,  0.9028,\n",
      "         0.7432,  0.3126,  1.2198,  0.4618,  0.8913, -0.0506,  0.0047, -2.2556],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7847, -0.7765, -0.6416, -0.0554,  2.0377,  0.3292,  0.5519, -1.0777,\n",
      "         0.3342, -1.7150,  1.6220, -0.6053, -0.5346,  0.9359,  0.1970,  0.2315,\n",
      "        -1.3903,  0.5409, -0.3770,  0.6721,  0.1926,  1.2066, -0.6656,  0.2635,\n",
      "         0.6336, -0.9095, -2.3961, -0.6811,  0.3678, -1.3803, -0.2859, -0.3698],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1169.3215, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   19,    7,   15, 2478,  168,   43,  234,   78,    6,   22,    5,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19,  23,  98, 360, 529,  10,  32,  78,   6,   5,   5,   2,   2,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 6.7687e-01,  1.2604e+00,  1.8108e+00,  ...,  2.4742e+00,\n",
      "          2.0423e+00,  2.1473e+00],\n",
      "        [-8.2489e+00, -9.5214e+00, -9.9711e+00,  ..., -1.2367e+01,\n",
      "         -1.0200e+01, -9.4170e+00],\n",
      "        [-6.2545e-04, -1.1368e+00,  2.4586e+00,  ...,  4.6127e+00,\n",
      "          4.1496e+00,  5.6025e+00],\n",
      "        ...,\n",
      "        [-3.1586e+00, -3.8488e+00, -3.4980e+00,  ..., -3.9469e+00,\n",
      "         -3.5949e+00, -2.7485e+00],\n",
      "        [-4.6386e+00, -6.0857e+00, -4.8174e+00,  ..., -4.5933e+00,\n",
      "         -4.2212e+00, -2.5913e+00],\n",
      "        [-5.0838e+00, -5.4422e+00, -5.1073e+00,  ..., -3.7853e+00,\n",
      "         -2.8037e+00, -2.6889e+00]], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '好', '一', '陣', '子', '沒', '看', '到', '你', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '得', '個', '都', '的', '有', '到', '你', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9576, -0.7905,  0.9868, -0.6444,  0.0368,  0.0268, -0.1856, -0.3672,\n",
      "         1.1012,  0.5533, -0.1026, -1.5931, -1.6060, -0.0420, -0.8562,  0.7732,\n",
      "        -1.1382, -0.0677, -0.7838,  1.3378,  1.6452, -0.7605,  1.8917,  0.8842,\n",
      "         0.7496,  0.3083,  1.2268,  0.4651,  0.9014, -0.0455,  0.0159, -2.2597],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7901, -0.7859, -0.6355, -0.0456,  2.0437,  0.3215,  0.5454, -1.0710,\n",
      "         0.3378, -1.7152,  1.6229, -0.6107, -0.5230,  0.9452,  0.2047,  0.2219,\n",
      "        -1.3840,  0.5450, -0.3672,  0.6719,  0.1861,  1.1978, -0.6755,  0.2576,\n",
      "         0.6395, -0.9006, -2.3806, -0.6879,  0.3722, -1.3765, -0.2915, -0.3772],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1618.1108, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3, 839, 360, 171, 529,  29,  30,  19,  23, 348, 350, 236,  64,   5,\n",
      "          2,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 19, 266, 266,  29,  23,  30,  19,  23,  29, 122,   5,  64,   5,   2,\n",
      "          5,   5,   5,   5,   5,   5,  33,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  1.0997,   1.6548,   1.5276,  ...,   2.5199,   2.1124,   1.4768],\n",
      "        [ -7.0816,  -8.4327,  -8.2191,  ...,  -8.7075, -10.8956,  -9.2754],\n",
      "        [ -0.8500,  -3.9080,  -2.9632,  ...,   2.5102,   4.7255,   6.5220],\n",
      "        ...,\n",
      "        [ -2.8774,  -3.1865,  -2.3872,  ...,  -2.9532,  -3.8503,  -3.2393],\n",
      "        [ -4.3298,  -3.6845,  -3.1750,  ...,  -2.6889,  -4.7920,  -4.7646],\n",
      "        [ -4.0326,  -2.8341,  -3.5185,  ...,  -2.2347,  -3.2950,  -2.7212]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '每', '個', '人', '都', '知', '道', '我', '不', '喜', '歡', '湯', '姆', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '天', '天', '知', '不', '道', '我', '不', '知', '欢', '。', '姆', '。', '<eos>', '。', '。', '。', '。', '。', '。', '？', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9560, -0.7964,  0.9859, -0.6473,  0.0394,  0.0346, -0.1836, -0.3672,\n",
      "         1.0930,  0.5511, -0.0994, -1.5917, -1.5972, -0.0363, -0.8618,  0.7819,\n",
      "        -1.1285, -0.0789, -0.7879,  1.3358,  1.6431, -0.7625,  1.8959,  0.8904,\n",
      "         0.7669,  0.3030,  1.2205,  0.4678,  0.9132, -0.0345,  0.0090, -2.2617],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7906, -0.7936, -0.6293, -0.0321,  2.0587,  0.3193,  0.5339, -1.0577,\n",
      "         0.3497, -1.7146,  1.6199, -0.6155, -0.5114,  0.9544,  0.2164,  0.2239,\n",
      "        -1.3784,  0.5489, -0.3565,  0.6628,  0.1878,  1.1852, -0.6771,  0.2553,\n",
      "         0.6545, -0.8924, -2.3642, -0.7126,  0.3720, -1.3762, -0.3038, -0.3904],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1342.5763, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,  193, 1912,   23, 1162,   15, 2071,  171,   97,   98,   10,  214,\n",
      "          59, 1006,  899,    5,    2,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193,  60,  32, 239,   6, 167, 128,  10,  98,  19,  44, 331,   5, 899,\n",
      "          5,   2,   5,   2,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  1.7725,   2.0355,   2.3828,  ...,   2.1511,   2.1586,   1.9535],\n",
      "        [ -8.5297, -10.0325, -11.0049,  ..., -10.1401, -10.8165, -10.1192],\n",
      "        [ -0.8844,  -2.3016,  -2.5959,  ...,   3.0983,   2.7929,   3.4212],\n",
      "        ...,\n",
      "        [ -3.5444,  -4.5687,  -3.6218,  ...,  -3.4631,  -3.6345,  -3.2833],\n",
      "        [ -4.3039,  -5.0119,  -4.7127,  ...,  -4.1295,  -4.6449,  -4.4071],\n",
      "        [ -4.9897,  -4.5972,  -5.4289,  ...,  -3.4105,  -3.1758,  -2.8020]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '这', '并', '不', '像', '一', '般', '人', '觉', '得', '的', '那', '么', '容', '易', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '是', '有', '要', '你', '个', '，', '的', '得', '我', '事', '样', '。', '易', '。', '<eos>', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9593, -0.7893,  0.9725, -0.6392,  0.0304,  0.0446, -0.1880, -0.3613,\n",
      "         1.1026,  0.5597, -0.0954, -1.5859, -1.6038, -0.0456, -0.8609,  0.7729,\n",
      "        -1.1384, -0.0746, -0.7821,  1.3313,  1.6444, -0.7549,  1.8952,  0.8814,\n",
      "         0.7643,  0.3090,  1.2241,  0.4705,  0.9160, -0.0390,  0.0122, -2.2614],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7920, -0.7979, -0.6363, -0.0260,  2.0541,  0.3211,  0.5307, -1.0622,\n",
      "         0.3422, -1.7170,  1.6130, -0.6147, -0.5115,  0.9479,  0.2150,  0.2129,\n",
      "        -1.3837,  0.5514, -0.3592,  0.6589,  0.1886,  1.1860, -0.6755,  0.2598,\n",
      "         0.6547, -0.8932, -2.3630, -0.7076,  0.3745, -1.3706, -0.2983, -0.3820],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1311.2261, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   24,  732,  942, 1175,   22, 2411,  649,    5,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([193, 134,  22, 163,  10,  22,   0,   5,   2,   5,   5,   5,   5,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[ 3.9677,  4.2283,  3.8420,  ...,  3.2169,  2.7469,  3.0061],\n",
      "        [-6.4960, -9.3955, -7.9603,  ..., -9.7210, -8.4898, -9.0023],\n",
      "        [-3.4088, -4.2011, -3.3408,  ...,  3.1923,  4.2901,  3.6360],\n",
      "        ...,\n",
      "        [-2.3930, -2.7699, -2.1664,  ..., -3.3897, -3.0944, -2.9974],\n",
      "        [-2.5306, -2.7969, -2.7550,  ..., -3.8802, -3.5187, -3.0871],\n",
      "        [-2.2889, -2.2681, -2.7721,  ..., -1.3170, -1.2331, -1.4289]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '会', '议', '接', '近', '了', '尾', '声', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['这', '上', '了', '在', '的', '了', '<unknown>', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9498, -0.7897,  0.9884, -0.6206,  0.0220,  0.0563, -0.1626, -0.3717,\n",
      "         1.0931,  0.5497, -0.1044, -1.5853, -1.6006, -0.0378, -0.8604,  0.7884,\n",
      "        -1.1207, -0.0810, -0.7796,  1.3181,  1.6261, -0.7614,  1.8858,  0.8741,\n",
      "         0.7662,  0.3046,  1.2290,  0.4721,  0.9246, -0.0334,  0.0155, -2.2596],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.8078, -0.8149, -0.6285, -0.0307,  2.0644,  0.3055,  0.5342, -1.0511,\n",
      "         0.3474, -1.7083,  1.6227, -0.6243, -0.4997,  0.9615,  0.2309,  0.2147,\n",
      "        -1.3804,  0.5688, -0.3616,  0.6542,  0.1793,  1.1922, -0.6963,  0.2445,\n",
      "         0.6528, -0.8778, -2.3413, -0.7131,  0.3883, -1.3679, -0.3071, -0.3961],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1404.6166, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,  514,  134,  723,   22,    5,  133, 1196,  597,  512,  106,\n",
      "          22,    5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([   6,   56,  163,  163,   10,   10,    2,   19,  413, 1984,   10,   33,\n",
      "           5,    2,    2,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
      "           5,    5,    5,    5,    5], device='cuda:0') tensor([[  2.8827,   2.8978,   3.1057,  ...,   2.5977,   2.6810,   2.2122],\n",
      "        [ -7.7462,  -9.9580, -10.4306,  ...,  -8.9925, -10.0202,  -9.7064],\n",
      "        [ -2.1346,  -1.9571,  -3.6310,  ...,   2.9468,   3.0659,   4.2989],\n",
      "        ...,\n",
      "        [ -3.4947,  -4.0845,  -3.0654,  ...,  -3.1719,  -3.2896,  -3.2746],\n",
      "        [ -3.8110,  -5.1583,  -4.2050,  ...,  -3.0936,  -3.3942,  -4.0732],\n",
      "        [ -4.4083,  -4.9062,  -3.9468,  ...,  -2.4110,  -2.3458,  -2.2499]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '该', '上', '床', '了', '。', '把', '收', '音', '机', '关', '了', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '们', '在', '在', '的', '的', '<eos>', '我', '麼', '界', '的', '？', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9633, -0.7892,  0.9858, -0.6208,  0.0264,  0.0383, -0.1708, -0.3667,\n",
      "         1.0691,  0.5347, -0.0918, -1.5686, -1.5942, -0.0486, -0.8813,  0.7740,\n",
      "        -1.1235, -0.0726, -0.7667,  1.3515,  1.6291, -0.7734,  1.8809,  0.8730,\n",
      "         0.7542,  0.3190,  1.2289,  0.4756,  0.9209, -0.0368,  0.0025, -2.2483],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7894, -0.8194, -0.6482, -0.0081,  2.0457,  0.3261,  0.5348, -1.0747,\n",
      "         0.3290, -1.7316,  1.5990, -0.6025, -0.5050,  0.9533,  0.2063,  0.1920,\n",
      "        -1.3614,  0.5481, -0.3423,  0.6484,  0.1833,  1.1759, -0.6905,  0.2762,\n",
      "         0.6540, -0.8651, -2.3570, -0.6936,  0.3904, -1.3766, -0.3110, -0.3774],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1425.8755, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,   10,  397,  573,  163,  193,  167, 1208, 1209,   35,   33,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([  6,  10, 834, 101,  10, 412, 164, 602, 391, 252,  33,   2,   2,  10,\n",
      "         33,  33,  33,  10,  33,  10,  33,  33,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  1.8994,   2.7416,   3.6877,  ...,   2.1363,   2.1748,   2.0611],\n",
      "        [ -7.8421, -10.8769, -10.0890,  ...,  -8.5250,  -8.3811, -10.0743],\n",
      "        [  2.7156,  -0.0906,  -1.8459,  ...,   2.4365,   2.9329,   4.2105],\n",
      "        ...,\n",
      "        [ -3.9169,  -4.3147,  -3.5056,  ...,  -2.7762,  -2.8955,  -3.3903],\n",
      "        [ -3.9391,  -4.6256,  -2.3508,  ...,  -3.0316,  -3.1808,  -4.4821],\n",
      "        [ -4.9726,  -5.1008,  -3.8778,  ...,  -1.8061,  -2.0481,  -2.8563]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '的', '学', '校', '在', '这', '个', '城', '市', '吗', '？', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['你', '的', '房', '生', '的', '哪', '裡', '書', '题', '嗎', '？', '<eos>', '<eos>', '的', '？', '？', '？', '的', '？', '的', '？', '？', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.6193e-01, -7.7715e-01,  9.8725e-01, -6.3048e-01,  3.0057e-02,\n",
      "         5.3052e-02, -1.8815e-01, -3.6071e-01,  1.0727e+00,  5.3427e-01,\n",
      "        -9.4796e-02, -1.5667e+00, -1.5938e+00, -4.1843e-02, -8.8279e-01,\n",
      "         7.7359e-01, -1.1128e+00, -6.4876e-02, -7.5837e-01,  1.3507e+00,\n",
      "         1.6355e+00, -7.7374e-01,  1.8861e+00,  8.6382e-01,  7.6163e-01,\n",
      "         3.2022e-01,  1.2305e+00,  4.7528e-01,  9.1685e-01, -3.7133e-02,\n",
      "        -1.3637e-03, -2.2442e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7870, -0.8320, -0.6641,  0.0092,  2.0403,  0.3298,  0.5194, -1.0859,\n",
      "         0.3200, -1.7398,  1.5848, -0.6012, -0.5040,  0.9458,  0.1972,  0.1758,\n",
      "        -1.3650,  0.5525, -0.3440,  0.6469,  0.1860,  1.1639, -0.6873,  0.2867,\n",
      "         0.6544, -0.8624, -2.3508, -0.6954,  0.3854, -1.3587, -0.3056, -0.3664],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1448.3655, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,    6,  173,  168,  366,  163,   73,   19,  974,  173, 1818,   24,\n",
      "           5,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 36,  10,  22,  10,  60,  19,  19,  10, 168,   5,   5,   5,   2,   5,\n",
      "          5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  2.4481,   2.8208,   3.3867,  ...,   1.9029,   1.8873,   2.2913],\n",
      "        [ -8.5164, -10.7765,  -9.1526,  ...,  -9.7820, -10.0890, -11.1438],\n",
      "        [  3.5900,   1.9297,   0.7387,  ...,   5.6286,   4.7690,   3.0462],\n",
      "        ...,\n",
      "        [ -3.8090,  -3.9736,  -2.0745,  ...,  -3.0109,  -3.2760,  -3.5120],\n",
      "        [ -4.8165,  -5.3286,  -2.3803,  ...,  -3.4431,  -4.0954,  -4.1589],\n",
      "        [ -5.1578,  -4.5119,  -2.6340,  ...,  -3.0060,  -2.9673,  -2.9759]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '你', '儿', '子', '正', '在', '和', '我', '女', '儿', '约', '会', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['他', '的', '了', '的', '是', '我', '我', '的', '子', '。', '。', '。', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9563, -0.7702,  0.9792, -0.6289,  0.0325,  0.0520, -0.1852, -0.3629,\n",
      "         1.0695,  0.5219, -0.0968, -1.5602, -1.5929, -0.0448, -0.8860,  0.7795,\n",
      "        -1.1003, -0.0648, -0.7486,  1.3447,  1.6186, -0.7835,  1.8830,  0.8663,\n",
      "         0.7600,  0.3232,  1.2457,  0.4671,  0.9134, -0.0354, -0.0026, -2.2346],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7873, -0.8287, -0.6639,  0.0184,  2.0394,  0.3338,  0.5088, -1.0816,\n",
      "         0.3253, -1.7314,  1.5830, -0.6082, -0.5041,  0.9462,  0.1979,  0.1828,\n",
      "        -1.3691,  0.5536, -0.3495,  0.6568,  0.1835,  1.1568, -0.6837,  0.2820,\n",
      "         0.6641, -0.8712, -2.3500, -0.7022,  0.3780, -1.3564, -0.3008, -0.3720],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1544.7273, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([  3,  19, 248,  23,  29,  30, 236,  64, 101,  22, 102,   5,   2,   1,\n",
      "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "          1,   1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([19, 23, 29, 29, 30, 63, 64, 10, 22,  5,  5,  2,  2,  2,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5], device='cuda:0') tensor([[  0.9463,   1.4339,   1.6850,  ...,   2.5300,   2.0925,   1.9706],\n",
      "        [ -7.1301,  -8.2025,  -9.2726,  ..., -10.4687,  -9.2299, -11.5389],\n",
      "        [ -0.4338,  -1.3939,  -2.0739,  ...,   2.9281,   4.1324,   4.6969],\n",
      "        ...,\n",
      "        [ -2.4730,  -3.2198,  -3.7344,  ...,  -3.6020,  -3.5081,  -4.0964],\n",
      "        [ -4.4560,  -5.8667,  -5.8173,  ...,  -3.3606,  -2.9862,  -4.5770],\n",
      "        [ -3.7683,  -4.3030,  -4.4105,  ...,  -3.5717,  -2.7062,  -3.6441]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '我', '還', '不', '知', '道', '湯', '姆', '生', '了', '病', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['我', '不', '知', '知', '道', '汤', '姆', '的', '了', '。', '。', '<eos>', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.4170e-01, -7.7541e-01,  9.7559e-01, -6.5286e-01,  4.0059e-02,\n",
      "         5.2372e-02, -1.8344e-01, -3.5872e-01,  1.0654e+00,  5.2714e-01,\n",
      "        -1.0482e-01, -1.5668e+00, -1.5828e+00, -4.1192e-02, -8.9664e-01,\n",
      "         7.8209e-01, -1.1054e+00, -6.9679e-02, -7.4934e-01,  1.3356e+00,\n",
      "         1.6407e+00, -7.7929e-01,  1.8815e+00,  8.7165e-01,  7.5727e-01,\n",
      "         3.1379e-01,  1.2365e+00,  4.8068e-01,  8.9154e-01, -2.3906e-02,\n",
      "        -1.1685e-03, -2.2353e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7936, -0.8253, -0.6595,  0.0171,  2.0425,  0.3272,  0.5027, -1.0757,\n",
      "         0.3277, -1.7243,  1.5867, -0.6206, -0.4967,  0.9446,  0.1991,  0.1791,\n",
      "        -1.3810,  0.5620, -0.3605,  0.6627,  0.1739,  1.1625, -0.6792,  0.2742,\n",
      "         0.6694, -0.8773, -2.3389, -0.7060,  0.3663, -1.3424, -0.3009, -0.3740],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1249.3190, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3,   15, 1443,  262,  171,  207,   97,  186,  187,  188,   10,  199,\n",
      "          57,  849,  387,   23,  221,  936,  614,    5,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([ 643,  360,  171, 1396,   10,  134,   22,  187,  188,   10,  834,  168,\n",
      "           5,    0,    5,    5,    5,    5,    5,    2,    2,    5,    5,    5,\n",
      "           5,    5,    5,    5,    5], device='cuda:0') tensor([[ 3.2377,  3.3651,  3.8751,  ...,  2.5766,  2.7976,  2.4343],\n",
      "        [-6.8507, -8.2247, -9.3127,  ..., -9.3976, -9.0880, -8.8121],\n",
      "        [-2.8899, -5.5426, -4.1133,  ...,  3.5574,  2.5911,  3.3479],\n",
      "        ...,\n",
      "        [-2.6174, -3.1733, -3.3608,  ..., -3.2933, -3.2176, -3.2516],\n",
      "        [-3.1301, -3.0656, -2.2445,  ..., -3.7577, -2.9068, -3.5435],\n",
      "        [-3.3124, -2.2244, -2.8646,  ..., -1.7690, -1.7895, -2.3207]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '一', '部', '分', '人', '感', '觉', 'T', 'o', 'm', '的', '行', '为', '举', '止', '不', '太', '合', '适', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['請', '個', '人', '鐘', '的', '上', '了', 'o', 'm', '的', '房', '子', '。', '<unknown>', '。', '。', '。', '。', '。', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-0.9499, -0.7671,  0.9634, -0.6470,  0.0470,  0.0433, -0.1901, -0.3502,\n",
      "         1.0656,  0.5278, -0.0924, -1.5571, -1.5855, -0.0453, -0.8983,  0.7774,\n",
      "        -1.0898, -0.0701, -0.7528,  1.3498,  1.6374, -0.7779,  1.8787,  0.8601,\n",
      "         0.7714,  0.3212,  1.2437,  0.4917,  0.8914, -0.0264,  0.0037, -2.2342],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7863, -0.8144, -0.6523,  0.0268,  2.0492,  0.3250,  0.4935, -1.0692,\n",
      "         0.3358, -1.7194,  1.5886, -0.6286, -0.4957,  0.9458,  0.1962,  0.1750,\n",
      "        -1.3806,  0.5635, -0.3599,  0.6693,  0.1717,  1.1459, -0.6663,  0.2787,\n",
      "         0.6886, -0.8889, -2.3363, -0.7136,  0.3520, -1.3453, -0.3087, -0.3792],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1583.5186, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Y label:  torch.Size([32, 30]) tensor([   3, 1894,   19,  132,   29,  128,  177, 1212,  280,  166, 2135,    5,\n",
      "           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1], device='cuda:0')\n",
      "y inference torch.Size([32, 2643, 29]) tensor([177,  19,  23,  29,  30, 177,  23, 280,  60,  22,   5,   2,   2,   2,\n",
      "          2,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "          5], device='cuda:0') tensor([[  1.9629,   1.7881,   2.0811,  ...,   1.9979,   2.0697,   1.0810],\n",
      "        [ -6.9501,  -9.0515,  -8.5203,  ..., -11.8559, -10.2982,  -9.0857],\n",
      "        [ -2.6921,  -2.0095,  -2.8365,  ...,   3.9669,   3.6937,   7.1868],\n",
      "        ...,\n",
      "        [ -1.6978,  -1.6717,  -2.2125,  ...,  -3.7797,  -3.1795,  -3.1201],\n",
      "        [ -3.5023,  -4.5848,  -5.0746,  ...,  -5.1252,  -4.3963,  -4.4299],\n",
      "        [ -3.2071,  -4.0103,  -3.5955,  ...,  -3.5637,  -2.9476,  -2.9857]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "y label seq:  ['<bos>', '据', '我', '所', '知', '，', '她', '仍', '然', '失', '踪', '。', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "y inference seq:  ['她', '我', '不', '知', '道', '她', '不', '然', '是', '了', '。', '<eos>', '<eos>', '<eos>', '<eos>', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。', '。']\n",
      "x embedding 0 tensor([-9.5874e-01, -7.5899e-01,  9.5747e-01, -6.5858e-01,  4.8125e-02,\n",
      "         2.9376e-02, -2.0850e-01, -3.3211e-01,  1.0577e+00,  5.2208e-01,\n",
      "        -7.5142e-02, -1.5477e+00, -1.6084e+00, -5.2060e-02, -9.1341e-01,\n",
      "         7.5647e-01, -1.0812e+00, -5.8482e-02, -7.4017e-01,  1.3639e+00,\n",
      "         1.6378e+00, -7.8163e-01,  1.8864e+00,  8.2594e-01,  7.6879e-01,\n",
      "         3.2449e-01,  1.2392e+00,  5.0138e-01,  8.8197e-01, -3.7839e-02,\n",
      "         2.0170e-03, -2.2304e+00], device='cuda:0',\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "y embedding 0 tensor([ 0.7897, -0.8088, -0.6384,  0.0343,  2.0580,  0.3210,  0.4789, -1.0519,\n",
      "         0.3542, -1.7111,  1.5944, -0.6379, -0.4958,  0.9515,  0.2063,  0.2005,\n",
      "        -1.3770,  0.5650, -0.3544,  0.6716,  0.1732,  1.1403, -0.6657,  0.2643,\n",
      "         0.7079, -0.8941, -2.3294, -0.7336,  0.3486, -1.3547, -0.3093, -0.3991],\n",
      "       device='cuda:0', grad_fn=<EmbeddingBackward>)\n",
      "loss  tensor(1531.7280, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def get_sequence(index):\n",
    "    seq = []\n",
    "    for i in index:\n",
    "        seq.append(target_words[i])\n",
    "    return seq\n",
    "        \n",
    "def train(data_loader, seq2seq, epoch, cross_loss):\n",
    "    optimizer = torch.optim.Adam(seq2seq.parameters(), lr=0.1)\n",
    "    count = 0\n",
    "    for _ in range(epoch):\n",
    "        for data in data_loader:\n",
    "            count += 1\n",
    "            x, y_label = data\n",
    "            # x, y shape=[batch, sequence length], here we permute to make their shape=[sequence length, batch]\n",
    "            x = x.permute(1, 0)\n",
    "            y_label = y_label.permute(1, 0)\n",
    "            # y_inference shape=[sequence length, batch, vocab_size]\n",
    "            y_inference = seq2seq(x, y_label[:-1, :])\n",
    "            # change shape for cross entropy\n",
    "            # y shape = [batch, sequence length]\n",
    "            # y inference shape = [batch, vocab size, sequence_length]\n",
    "            y_label = y_label.permute(1, 0)\n",
    "            y_inference = y_inference.permute(1, 2, 0)\n",
    "            mask = (y_label != target_dict[\"<pad>\"]).float()\n",
    "            arg_max = y_inference.argmax(dim=1)\n",
    "            # print(\"argmax\", arg_max.shape, arg_max)\n",
    "            loss = torch.mul(cross_loss(y_inference[:, :, :], y_label[:, 1:]), mask[:, 1:])\n",
    "            # print(\"loss\", loss, \"y_label\", y_label)\n",
    "            loss = loss.sum()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if count % 100 == 0:\n",
    "                print(\"Y label: \", y_label.shape, y_label[0])\n",
    "                print(\"y inference\", y_inference.shape, arg_max[0], y_inference[0])\n",
    "                print(\"y label seq: \", get_sequence(y_label[0]))\n",
    "                print(\"y inference seq: \", get_sequence(arg_max[0]))\n",
    "                print(\"x embedding 0\", seq2seq.encoder_.word2vec(torch.tensor(0).cuda()))\n",
    "                print(\"y embedding 0\", seq2seq.decoder_.word2vec(torch.tensor(0).cuda()))\n",
    "                print(\"loss \", loss)\n",
    "\n",
    "seq_data_set = SeqDataset(source_lines=source_sequence,\n",
    "                          target_lines=target_sequence,\n",
    "                          source_words=source_words,\n",
    "                          target_words=target_words,\n",
    "                          source_dict=source_dict,\n",
    "                          target_dict=target_dict)\n",
    "train_data_loader = DataLoader(dataset=seq_data_set, batch_size=32, shuffle=True)\n",
    "seq2seq = Seq2Seq(GRUEncoder(len(source_words), 32), GRUDecoder(len(target_words), 32))\n",
    "seq2seq.to(device)\n",
    "cross_loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "train(train_data_loader, seq2seq, 10, cross_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data_set = SeqDataset(source_lines=source_sequence,\n",
    "                          target_lines=target_sequence,\n",
    "                          source_words=source_words,\n",
    "                          target_words=target_words,\n",
    "                          source_dict=source_dict,\n",
    "                          target_dict=target_dict)\n",
    "train_data_loader = DataLoader(dataset=seq_data_set, batch_size=32, shuffle=True)\n",
    "\n",
    "seq2seq = Seq2Seq(GRUEncoder(len(source_words), 96), GRUDecoder(len(target_words), 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    def __getitem__(self, index):\n",
    "        return embedding[index]\n",
    "    def __len__(self):\n",
    "        return len(embedding)\n",
    "\n",
    "data_loader = DataLoader(dataset=EmbeddingDataset(), batch_size=2)\n",
    "for data in data_loader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "-math.log(math.exp(0) / (math.exp(1) * 2 + math.exp(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        print(\"unweighted\", unweighted_loss)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "loss = MaskedSoftmaxCELoss()\n",
    "print(loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0])))\n",
    "print(nn.CrossEntropyLoss(reduction=\"none\")(torch.ones(3, 10, 4), torch.ones((3, 4), dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b84ff043d1ce40a48e7a6204d380e64e0c4bd8261b351461971bed57374200c1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
